{"cells":[{"cell_type":"markdown","metadata":{"id":"9nTWu0GL8Ifz"},"source":["## Lesson 10 - Experiment Toolkit\n","- 이번 실습 자료에서는 강의시간에 다루었던 Tensorboard & wandb 연동 코드에 대해 실습을 진행합니다.\n","    1. 실습을 진행하기 앞서 먼저 'pip install wandb'를 통해 wandb를 설치하시고, 'wandb.ai' 홈페이지에서 회원가입을 진행 합니다.\n","    2. 터미널 창에서 wandb login 을 입력하여 사용자 계정과 로컬 환경을 연결합니다.\n","        - 사용자 계정은 wandb.ai 홈페이지에서 로그인 후 profile - Settings - API Keys 항목에서 API키를 생성하여 연결할 수 있습니다. 최초 한번 진행됩니다."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"SjI2skhzWUQu","scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting wandb\n","  Downloading wandb-0.12.10-py2.py3-none-any.whl (1.7 MB)\n","\u001b[K     |████████████████████████████████| 1.7 MB 19.2 MB/s eta 0:00:01\n","\u001b[?25hCollecting shortuuid>=0.5.0\n","  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n","Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (5.7.2)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.8/site-packages (from wandb) (2.8.2)\n","Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (2.24.0)\n","Collecting promise<3,>=2.0\n","  Downloading promise-2.3.tar.gz (19 kB)\n","Requirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (3.17.3)\n","Collecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.5.6-py2.py3-none-any.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 83.4 MB/s eta 0:00:01\n","\u001b[?25hCollecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting yaspin>=1.0.0\n","  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n","Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (1.15.0)\n","Requirement already satisfied: PyYAML in /opt/conda/lib/python3.8/site-packages (from wandb) (5.3.1)\n","Collecting GitPython>=1.0.0\n","  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n","\u001b[K     |████████████████████████████████| 181 kB 49.8 MB/s eta 0:00:01\n","\u001b[?25hCollecting Click!=8.0.0,>=7.0\n","  Downloading click-8.0.4-py3-none-any.whl (97 kB)\n","\u001b[K     |████████████████████████████████| 97 kB 8.5 MB/s  eta 0:00:01\n","\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (1.25.11)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Collecting termcolor<2.0.0,>=1.1.0\n","  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 3.1 MB/s  eta 0:00:01\n","\u001b[?25hCollecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Building wheels for collected packages: promise, pathtools, termcolor\n","  Building wheel for promise (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21494 sha256=1229df30d6b754633324a04117e653a3abce8e7f462b9576dbc0238460ab8ff3\n","  Stored in directory: /opt/ml/.cache/pip/wheels/54/aa/01/724885182f93150035a2a91bce34a12877e8067a97baaf5dc8\n","  Building wheel for pathtools (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8785 sha256=f34914c9af3d0914ffaebd8faf79ba5f7eefad8848383387b2e63c1821212d26\n","  Stored in directory: /opt/ml/.cache/pip/wheels/4c/8e/7e/72fbc243e1aeecae64a96875432e70d4e92f3d2d18123be004\n","  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=24646d47673892ac09c544610ff685625c96c7972759c409d8d3fd2b801e53a0\n","  Stored in directory: /opt/ml/.cache/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n","Successfully built promise pathtools termcolor\n","Installing collected packages: shortuuid, promise, pathtools, sentry-sdk, docker-pycreds, termcolor, yaspin, smmap, gitdb, GitPython, Click, wandb\n","Successfully installed Click-8.0.4 GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 promise-2.3 sentry-sdk-1.5.6 shortuuid-1.0.8 smmap-5.0.0 termcolor-1.1.0 wandb-0.12.10 yaspin-2.1.0\n"]}],"source":["!pip install wandb"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"PmiNC_MY8Ifv"},"outputs":[],"source":["import random\n","import os, sys\n","\n","import numpy as np\n","import torch\n","from torch.utils.data import Subset\n","from torch.optim import Adam\n","from torch.optim.lr_scheduler import StepLR\n","from torch.utils.tensorboard import SummaryWriter\n","import torchvision\n","\n","from sklearn.model_selection import StratifiedKFold\n","\n","sys.path.append(os.path.abspath('..'))\n","\n","# BaseLine 코드로 주어진 dataset.py model.py, loss.py를 Import 합니다.\n","from dataset import MaskBaseDataset, BaseAugmentation\n","from model import *\n","from loss import create_criterion\n","\n","sys.path.append('../')\n","\n","import wandb\n","\n","def seed_everything(seed):\n","    \"\"\"\n","    동일한 조건으로 학습을 할 때, 동일한 결과를 얻기 위해 seed를 고정시킵니다.\n","    \n","    Args:\n","        seed: seed 정수값\n","    \"\"\"\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    np.random.seed(seed)\n","    random.seed(seed)\n","seed_everything(42)"]},{"cell_type":"markdown","metadata":{"id":"ajpxZtFu8If0"},"source":["### Model Parameter Setting"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"veN3QHOc8If0"},"outputs":[],"source":["# -- parameters\n","# img_root = '학습 이미지 폴더의 경로를 입력해주세요.'\n","\n","val_split = 0.4  # validation dataset의 비율\n","batch_size = 64\n","num_workers = 4\n","num_classes = 18\n","\n","num_epochs = 100  # 학습할 epoch의 수\n","lr = 1e-4\n","lr_decay_step = 10\n","criterion_name = 'cross_entropy'\n","\n","train_log_interval = 20  # logging할 iteration의 주기\n","name = \"02_model_results\"  # 결과를 저장하는 폴더의 이름\n","\n","# -- settings\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")"]},{"cell_type":"markdown","metadata":{"id":"DPjsk40V8If1"},"source":["### wandb init\n","- wandb를 사용하기 앞서 먼저 초기화를 진행하는데 이 때, 모델 학습에 사용할 파라미터를 같이 전달할 수 있습니다."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"CzwjAzWC8If2"},"outputs":[{"name":"stderr","output_type":"stream","text":["Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m No API key specified.\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /opt/ml/.netrc\n"]},{"data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/inbeomi/ml-specialmission_answer/runs/3qfzsus3\" target=\"_blank\">zany-glade-1</a></strong> to <a href=\"https://wandb.ai/inbeomi/ml-specialmission_answer\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/inbeomi/ml-specialmission_answer/runs/3qfzsus3?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7ff931fe14c0>"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# -- wandb initialize with configuration\n","wandb.init(config={\"batch_size\": batch_size,\n","                   \"lr\"        : lr,\n","                   \"epochs\"    : num_epochs,\n","                   \"name\"      : name,\n","                   \"criterion_name\" : criterion_name})"]},{"cell_type":"markdown","metadata":{"id":"n8n_d4CX8If2"},"source":["### Training process"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"CYncGKTn8If2"},"outputs":[],"source":["from torchvision.models import vgg19_bn\n","\n","# 데이터셋 생성\n","data_dir = '/opt/ml/input/data/train/images'\n","dataset = MaskBaseDataset(data_dir)\n","\n","# Augmentation Transform 생성\n","transform = BaseAugmentation(\n","    resize=[128, 96],\n","    mean=dataset.mean,\n","    std=dataset.std,\n",")\n","\n","# 데이터셋 준비\n","dataset.set_transform(transform)\n","n_val = int(len(dataset) * val_split)\n","n_train = len(dataset) - n_val\n","train_set, val_set = torch.utils.data.random_split(dataset, [n_train, n_val])\n","\n","# Train Valid DataLoader 생성\n","train_loader = torch.utils.data.DataLoader(\n","    train_set,\n","    batch_size=batch_size,\n","    num_workers=num_workers,\n","    drop_last=True,\n","    shuffle=True\n",")\n","\n","val_loader = torch.utils.data.DataLoader(\n","    val_set,\n","    batch_size=batch_size,\n","    num_workers=num_workers,\n","    drop_last=True,\n","    shuffle=False\n",")\n","\n","# -- model\n","model = vgg19_bn(pretrained=True)\n","model.classifier = nn.Sequential(\n","    nn.Linear(512 * 7 * 7, 4096),\n","    nn.ReLU(True),\n","    nn.Dropout(),\n","    nn.Linear(4096, 4096),\n","    nn.ReLU(True),\n","    nn.Dropout(),\n","    nn.Linear(4096, num_classes),\n",")\n","model.to(device)\n","\n","# -- loss & metric\n","criterion = create_criterion(criterion_name)\n","train_params = [{'params': getattr(model, 'features').parameters(), 'lr': lr / 10, 'weight_decay':5e-4},\n","                {'params': getattr(model, 'classifier').parameters(), 'lr': lr, 'weight_decay':5e-4}]\n","optimizer = Adam(train_params)\n","scheduler = StepLR(optimizer, lr_decay_step, gamma=0.5)"]},{"cell_type":"markdown","metadata":{"id":"X2X1yK_48If2"},"source":["### Tensorboard\n","- Tensorboard는 먼저 SummaryWriter 객체에 log_dir 인자(로그를 저장할 디렉토리 경로)를 전달하여 로그를 저장할 준비를 합니다. \n","    - 특정 주기마다 logger.add_scaler(이름, 값, 글로벌 스텝)을 전달하여 스칼라 값 로그를 기록합니다. \n","    - 특정 주기마다 logger.add_image(이미지 그리드)를 전달하여 이미지 로그를 기록합니다. \n","        - 여기에서는 train step에서 각 이미지들이 어떤식으로 Transform 되는지 기록해보겠습니다.\n","- 터미널에서 tensorboard --logdir='로그를 저장한 디렉토리 경로' 를 입력하여 텐서보드를 실행해 로그 기록을 확인할 수 있습니다.\n","\n","### wandb\n","- wandb는 이전에 init 함수를 통해 초기화를 마쳤으므로 특정 주기마다 wandb.log({이름: 값, ...})를 전달하여 로그를 기록합니다.\n","- wandb.ai 홈페이지에서 로그 기록을 확인할 수 있습니다."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"aDc0B9RS8If3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch[0/100](20/177) || training loss 2.282 || training accuracy 30.31% || lr [1e-05, 0.0001]\n","Epoch[0/100](40/177) || training loss 1.694 || training accuracy 49.14% || lr [1e-05, 0.0001]\n","Epoch[0/100](60/177) || training loss 1.277 || training accuracy 61.95% || lr [1e-05, 0.0001]\n","Epoch[0/100](80/177) || training loss 1.006 || training accuracy 68.05% || lr [1e-05, 0.0001]\n","Epoch[0/100](100/177) || training loss 0.8431 || training accuracy 73.44% || lr [1e-05, 0.0001]\n","Epoch[0/100](120/177) || training loss 0.7508 || training accuracy 76.09% || lr [1e-05, 0.0001]\n","Epoch[0/100](140/177) || training loss 0.6551 || training accuracy 79.30% || lr [1e-05, 0.0001]\n","Epoch[0/100](160/177) || training loss 0.6569 || training accuracy 78.91% || lr [1e-05, 0.0001]\n","Calculating validation results...\n","New best model for val accuracy! saving the model..\n","[Val] acc : 84.74%, loss: 0.46 || best acc : 84.74%, best loss: 0.46\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-19e8c3b5e559>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mloss_value\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mmatches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtrain_log_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["os.makedirs(os.path.join(os.getcwd(), 'results', name), exist_ok=True)\n","\n","counter = 0\n","patience = 10\n","accumulation_steps = 2\n","best_val_acc = 0\n","best_val_loss = np.inf\n","\n","# Tensorboard 로그를 저장할 경로 지정\n","logger = SummaryWriter(log_dir=f\"logdir/{name}\")\n","for epoch in range(num_epochs):\n","    # train loop\n","    model.train()\n","    loss_value = 0\n","    matches = 0\n","    \n","    for idx, train_batch in enumerate(train_loader):\n","        inputs, labels = train_batch\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","\n","        outs = model(inputs)\n","        preds = torch.argmax(outs, dim=-1)\n","        loss = criterion(outs, labels)\n","\n","        loss.backward()\n","        \n","        # -- Gradient Accumulation\n","        if (idx+1) % accumulation_steps == 0:\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","        loss_value += loss.item()\n","        matches += (preds == labels).sum().item()\n","        if (idx + 1) % train_log_interval == 0:\n","            train_loss = loss_value / train_log_interval\n","            train_acc = matches / batch_size / train_log_interval\n","            current_lr = scheduler.get_last_lr()\n","            print(\n","                f\"Epoch[{epoch}/{num_epochs}]({idx + 1}/{len(train_loader)}) || \"\n","                f\"training loss {train_loss:4.4} || training accuracy {train_acc:4.2%} || lr {current_lr}\"\n","            )\n","            \n","            # Tensorboard 학습 단계에서 Loss, Accuracy 로그 저장\n","            logger.add_scalar(\"Train/loss\", train_loss, epoch * len(train_loader) + idx)\n","            logger.add_scalar(\"Train/accuracy\", train_acc, epoch * len(train_loader) + idx)\n","\n","            loss_value = 0\n","            matches = 0\n","            \n","            # wandb 학습 단계에서 Loss, Accuracy 로그 저장\n","            wandb.log({\n","                \"Train loss\": train_loss,\n","                \"Train acc\" : train_acc\n","            })\n","    \n","    # 각 에폭의 마지막 input 이미지로 grid view 생성\n","    img_grid = torchvision.utils.make_grid(inputs)\n","    # Tensorboard에 train input 이미지 기록\n","    logger.add_image(f'{epoch}_train_input_img', img_grid, epoch)\n","\n","    scheduler.step()\n","\n","    # val loop\n","    with torch.no_grad():\n","        print(\"Calculating validation results...\")\n","        model.eval()\n","        val_loss_items = []\n","        val_acc_items = []\n","        for val_batch in val_loader:\n","            inputs, labels = val_batch\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            outs = model(inputs)\n","            preds = torch.argmax(outs, dim=-1)\n","\n","            loss_item = criterion(outs, labels).item()\n","            acc_item = (labels == preds).sum().item()\n","            val_loss_items.append(loss_item)\n","            val_acc_items.append(acc_item)\n","\n","        val_loss = np.sum(val_loss_items) / len(val_loader)\n","        val_acc = np.sum(val_acc_items) / len(val_set)\n","        \n","        # Callback1: validation accuracy가 향상될수록 모델을 저장합니다.\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","        if val_acc > best_val_acc:\n","            print(\"New best model for val accuracy! saving the model..\")\n","            torch.save(model.state_dict(), f\"results/{name}/{epoch:03}_accuracy_{val_acc:4.2%}.ckpt\")\n","            best_val_acc = val_acc\n","            counter = 0\n","        else:\n","            counter += 1\n","        # Callback2: patience 횟수 동안 성능 향상이 없을 경우 학습을 종료시킵니다.\n","        if counter > patience:\n","            print(\"Early Stopping...\")\n","            break\n","        \n","        print(\n","            f\"[Val] acc : {val_acc:4.2%}, loss: {val_loss:4.2} || \"\n","            f\"best acc : {best_val_acc:4.2%}, best loss: {best_val_loss:4.2}\"\n","        )\n","        # Tensorboard 검증 단계에서 Loss, Accuracy 로그 저장\n","        logger.add_scalar(\"Val/loss\", val_loss, epoch)\n","        logger.add_scalar(\"Val/accuracy\", val_acc, epoch)\n","\n","        # wandb 검증 단계에서 Loss, Accuracy 로그 저장\n","        wandb.log({\n","            \"Valid loss\": val_loss,\n","            \"Valid acc\" : val_acc\n","        })\n","      "]}],"metadata":{"colab":{"collapsed_sections":[],"name":"10_Experiment Toolkit (정답).ipynb의 사본","provenance":[{"file_id":"18jWJOfJ_KL-o_z8W7aal6GeAU5H2SFkr","timestamp":1645695040062}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}
