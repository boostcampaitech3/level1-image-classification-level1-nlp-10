{"cells":[{"cell_type":"markdown","id":"-MS3bWUNUSgz","metadata":{"id":"-MS3bWUNUSgz"},"source":["## Lesson 6 - Pretrained Model\n"," - 이번 실습 자료에서는 강의시간에 다루었던 torchvision 을 사용하여 pretrained 모델을 사용하는 방법에 대해 실습하겠습니다.\n"," - torchvision 의 pretrained model 리스트는 다음과 같습니다\n"," \n"," [List of torchvision models](https://github.com/pytorch/vision/blob/master/torchvision/models/__init__.py#L1-L14)\n","```\n","from .alexnet import *\n","from .resnet import *\n","from .vgg import *\n","from .squeezenet import *\n","from .inception import *\n","from .densenet import *\n","from .googlenet import *\n","from .mobilenet import *\n","from .mnasnet import *\n","from .shufflenetv2 import *\n","from . import segmentation\n","from . import detection\n","from . import video\n","from . import quantization\n","```"]},{"cell_type":"code","execution_count":1,"id":"QfXG-tzwUSgv","metadata":{"id":"QfXG-tzwUSgv"},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"]},{"cell_type":"markdown","id":"D2BlaYvVUSg0","metadata":{"id":"D2BlaYvVUSg0"},"source":["#### 가장 기본이라고 할 수 있는 Alextnet 모델 아키텍쳐를 사용해보겠습니다."]},{"cell_type":"code","execution_count":4,"id":"8PT7gW-wUSg0","metadata":{"id":"8PT7gW-wUSg0","scrolled":true},"outputs":[{"data":{"text/plain":["AlexNet(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n","    (1): ReLU(inplace=True)\n","    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (4): ReLU(inplace=True)\n","    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (7): ReLU(inplace=True)\n","    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (9): ReLU(inplace=True)\n","    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.5, inplace=False)\n","    (1): Linear(in_features=9216, out_features=4096, bias=True)\n","    (2): ReLU(inplace=True)\n","    (3): Dropout(p=0.5, inplace=False)\n","    (4): Linear(in_features=4096, out_features=4096, bias=True)\n","    (5): ReLU(inplace=True)\n","    (6): Linear(in_features=4096, out_features=1000, bias=True)\n","  )\n",")"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["from torchvision.models import alexnet\n","model = alexnet()\n","model # model.__repr__ ? __repre__는 객체의 공식적인 정보를, __str__은 비공식적인 정보를 출력함.\n"]},{"cell_type":"markdown","id":"kzOWtmBxUSg2","metadata":{"id":"kzOWtmBxUSg2"},"source":["#### Alexnet 의 pretrained 버전 또한 쉽게 불러올 수 있습니다."]},{"cell_type":"code","execution_count":5,"id":"36Rqc5-OUSg2","metadata":{"id":"36Rqc5-OUSg2","scrolled":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\" to /opt/ml/.cache/torch/hub/checkpoints/alexnet-owt-4df8aa71.pth\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fddc971f0c754f58a92e9ff11718744d","version_major":2,"version_minor":0},"text/plain":["HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=244418560.0), HTML(value='')))"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"data":{"text/plain":["AlexNet(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n","    (1): ReLU(inplace=True)\n","    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (4): ReLU(inplace=True)\n","    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (7): ReLU(inplace=True)\n","    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (9): ReLU(inplace=True)\n","    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.5, inplace=False)\n","    (1): Linear(in_features=9216, out_features=4096, bias=True)\n","    (2): ReLU(inplace=True)\n","    (3): Dropout(p=0.5, inplace=False)\n","    (4): Linear(in_features=4096, out_features=4096, bias=True)\n","    (5): ReLU(inplace=True)\n","    (6): Linear(in_features=4096, out_features=1000, bias=True)\n","  )\n",")"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["model = alexnet(pretrained=True) # default 값으로는 false로 되어 있음\n","model"]},{"cell_type":"markdown","id":"3799RyCBUSg3","metadata":{"id":"3799RyCBUSg3"},"source":["#### torchvision 에서 해당 모델을 어떤 식으로 구현하였는지 직접 확인해보면 매우 도움이 많으 됩니다.\n","Example:\n","[source code](https://github.com/pytorch/vision/blob/master/torchvision/models/alexnet.py#L15-L50)\n","```\n","class AlexNet(nn.Module):\n","\n","    def __init__(self, num_classes=1000):\n","        super(AlexNet, self).__init__()\n","        self.features = nn.Sequential(\n","            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2),\n","            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2),\n","            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2),\n","        )\n","        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n","        self.classifier = nn.Sequential(\n","            nn.Dropout(),\n","            nn.Linear(256 * 6 * 6, 4096),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(),\n","            nn.Linear(4096, 4096),\n","            nn.ReLU(inplace=True),\n","            nn.Linear(4096, num_classes),\n","        )\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = self.avgpool(x)\n","        x = torch.flatten(x, 1) # classifier 하기 전에 flatten하게 만들어 주네\n","        x = self.classifier(x)\n","        return x\n","```"]},{"cell_type":"markdown","id":"GCagXJS2USg4","metadata":{"id":"GCagXJS2USg4"},"source":["#### 다른 모델들( e.g. vgg19, resnet18) 도 같은 방법으로 손 쉽게 사용할 수 있습니다."]},{"cell_type":"code","execution_count":6,"id":"tsZbkfObUSg5","metadata":{"id":"tsZbkfObUSg5","scrolled":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/vgg19_bn-c79401a0.pth\" to /opt/ml/.cache/torch/hub/checkpoints/vgg19_bn-c79401a0.pth\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"06abfaaed4dc47948872cd77ba4d58fb","version_major":2,"version_minor":0},"text/plain":["HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=574769405.0), HTML(value='')))"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"data":{"text/plain":["VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU(inplace=True)\n","    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (9): ReLU(inplace=True)\n","    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (12): ReLU(inplace=True)\n","    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (16): ReLU(inplace=True)\n","    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (19): ReLU(inplace=True)\n","    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (22): ReLU(inplace=True)\n","    (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (25): ReLU(inplace=True)\n","    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (29): ReLU(inplace=True)\n","    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (32): ReLU(inplace=True)\n","    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (35): ReLU(inplace=True)\n","    (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (38): ReLU(inplace=True)\n","    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (42): ReLU(inplace=True)\n","    (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (45): ReLU(inplace=True)\n","    (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (48): ReLU(inplace=True)\n","    (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (51): ReLU(inplace=True)\n","    (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=4096, out_features=4096, bias=True)\n","    (4): ReLU(inplace=True)\n","    (5): Dropout(p=0.5, inplace=False)\n","    (6): Linear(in_features=4096, out_features=1000, bias=True)\n","  )\n",")"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["from torchvision.models import vgg19_bn\n","model = vgg19_bn(pretrained=True)\n","model"]},{"cell_type":"markdown","id":"foiF_enTUSg5","metadata":{"id":"foiF_enTUSg5"},"source":["#### Pretrained 모델을 내 태스크에 맞게 어떻게 사용할 수 있나요?\n"," - Trochvision 모델들은 보통 feature-extraction 파트, task-specific 파트로 크게 두 가지로 구성되어 있습니다.\n"," - Task specific 파트는 모델의 태스크(이미지 분류, 객체 인식 등) 에 따라 모두 다릅니다.\n"," - 심지어 같은 이미지 분류 안에서도, 어떤 데이터셋으로 pretrain 하였느냐에 따라 다를 수 있습니다.\n"," - 따라서, 우리도 우리 테스크에 맞게 task specific 파트는 새로 정의하여 사용하여야 합니다."]},{"cell_type":"markdown","id":"nYv1DZ69USg6","metadata":{"id":"nYv1DZ69USg6"},"source":[" - 주로 이미지넷 데이터셋을 사용하여 pretrain 을 하기에 output_dim=1000 인 경우가 많습니다.\n"," - 따라서 우리 태스크의 클래스 갯수(18)에 맞게 재정의하여 사용할 수 있습니다."]},{"cell_type":"code","execution_count":9,"id":"xQIxW_QRUSg6","metadata":{"id":"xQIxW_QRUSg6","scrolled":true},"outputs":[{"data":{"text/plain":["VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU(inplace=True)\n","    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (9): ReLU(inplace=True)\n","    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (12): ReLU(inplace=True)\n","    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (16): ReLU(inplace=True)\n","    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (19): ReLU(inplace=True)\n","    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (22): ReLU(inplace=True)\n","    (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (25): ReLU(inplace=True)\n","    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (29): ReLU(inplace=True)\n","    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (32): ReLU(inplace=True)\n","    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (35): ReLU(inplace=True)\n","    (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (38): ReLU(inplace=True)\n","    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (42): ReLU(inplace=True)\n","    (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (45): ReLU(inplace=True)\n","    (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (48): ReLU(inplace=True)\n","    (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (51): ReLU(inplace=True)\n","    (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=4096, out_features=4096, bias=True)\n","    (4): ReLU(inplace=True)\n","    (5): Dropout(p=0.5, inplace=False)\n","    (6): Linear(in_features=4096, out_features=18, bias=True)\n","  )\n",")"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["num_classes = 18\n","model = vgg19_bn(pretrained=True)\n","model.classifier = nn.Sequential( # classifier를 따로 만들어서 overwriting을 하는 식으로 함.\n","    nn.Linear(512 * 7 * 7, 4096),\n","    nn.ReLU(True), # inplace=True -> inplace: can optionally do the operation in-place. Default: ``False``\n","    nn.Dropout(),\n","    nn.Linear(4096, 4096),\n","    nn.ReLU(True),\n","    nn.Dropout(),\n","    nn.Linear(4096, num_classes),\n",")\n","\n","model"]},{"cell_type":"markdown","id":"bkuxurF2USg7","metadata":{"id":"bkuxurF2USg7"},"source":["#### Weight Freeze\n"," - Weight freeze 란 해당 모듈의 graident 는 역전파 하지 않아 학습을 하지 않는다는 의미입니다.\n"," - 예를 들어, 우리가 하려는 태스크가 pretrain 한 태스크와 매우 유사하다면, feature 파트는 freeze 하여 학습하지 않고 새로 정의한 task specific 파트만 학습하는 것이 좋은 방법일 수 있습니다.\n"," - weight freeze 는 `requires_grad` 를 사용하여 쉽게 구현할 수 있습니다. "]},{"cell_type":"code","execution_count":10,"id":"Qr2vjssZUSg7","metadata":{"id":"Qr2vjssZUSg7","scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["파라미터 features.0.weight    가 gradient 를 tracking 하나요? -> False\n","파라미터 features.0.bias      가 gradient 를 tracking 하나요? -> False\n","파라미터 features.1.weight    가 gradient 를 tracking 하나요? -> False\n","파라미터 features.1.bias      가 gradient 를 tracking 하나요? -> False\n","파라미터 features.3.weight    가 gradient 를 tracking 하나요? -> False\n","파라미터 features.3.bias      가 gradient 를 tracking 하나요? -> False\n","파라미터 features.4.weight    가 gradient 를 tracking 하나요? -> False\n","파라미터 features.4.bias      가 gradient 를 tracking 하나요? -> False\n","파라미터 features.7.weight    가 gradient 를 tracking 하나요? -> False\n","파라미터 features.7.bias      가 gradient 를 tracking 하나요? -> False\n","파라미터 features.8.weight    가 gradient 를 tracking 하나요? -> False\n","파라미터 features.8.bias      가 gradient 를 tracking 하나요? -> False\n","파라미터 features.10.weight   가 gradient 를 tracking 하나요? -> False\n","파라미터 features.10.bias     가 gradient 를 tracking 하나요? -> False\n","파라미터 features.11.weight   가 gradient 를 tracking 하나요? -> False\n","파라미터 features.11.bias     가 gradient 를 tracking 하나요? -> False\n","파라미터 features.14.weight   가 gradient 를 tracking 하나요? -> False\n","파라미터 features.14.bias     가 gradient 를 tracking 하나요? -> False\n","파라미터 features.15.weight   가 gradient 를 tracking 하나요? -> False\n","파라미터 features.15.bias     가 gradient 를 tracking 하나요? -> False\n","파라미터 features.17.weight   가 gradient 를 tracking 하나요? -> False\n","파라미터 features.17.bias     가 gradient 를 tracking 하나요? -> False\n","파라미터 features.18.weight   가 gradient 를 tracking 하나요? -> False\n","파라미터 features.18.bias     가 gradient 를 tracking 하나요? -> False\n","파라미터 features.20.weight   가 gradient 를 tracking 하나요? -> False\n","파라미터 features.20.bias     가 gradient 를 tracking 하나요? -> False\n","파라미터 features.21.weight   가 gradient 를 tracking 하나요? -> False\n","파라미터 features.21.bias     가 gradient 를 tracking 하나요? -> False\n","파라미터 features.23.weight   가 gradient 를 tracking 하나요? -> False\n","파라미터 features.23.bias     가 gradient 를 tracking 하나요? -> False\n","파라미터 features.24.weight   가 gradient 를 tracking 하나요? -> False\n","파라미터 features.24.bias     가 gradient 를 tracking 하나요? -> False\n","파라미터 features.27.weight   가 gradient 를 tracking 하나요? -> False\n","파라미터 features.27.bias     가 gradient 를 tracking 하나요? -> False\n","파라미터 features.28.weight   가 gradient 를 tracking 하나요? -> False\n","파라미터 features.28.bias     가 gradient 를 tracking 하나요? -> False\n","파라미터 features.30.weight   가 gradient 를 tracking 하나요? -> False\n","파라미터 features.30.bias     가 gradient 를 tracking 하나요? -> False\n","파라미터 features.31.weight   가 gradient 를 tracking 하나요? -> False\n","파라미터 features.31.bias     가 gradient 를 tracking 하나요? -> False\n","파라미터 features.33.weight   가 gradient 를 tracking 하나요? -> False\n","파라미터 features.33.bias     가 gradient 를 tracking 하나요? -> False\n","파라미터 features.34.weight   가 gradient 를 tracking 하나요? -> False\n","파라미터 features.34.bias     가 gradient 를 tracking 하나요? -> False\n","파라미터 features.36.weight   가 gradient 를 tracking 하나요? -> False\n","파라미터 features.36.bias     가 gradient 를 tracking 하나요? -> False\n","파라미터 features.37.weight   가 gradient 를 tracking 하나요? -> False\n","파라미터 features.37.bias     가 gradient 를 tracking 하나요? -> False\n","파라미터 features.40.weight   가 gradient 를 tracking 하나요? -> False\n","파라미터 features.40.bias     가 gradient 를 tracking 하나요? -> False\n","파라미터 features.41.weight   가 gradient 를 tracking 하나요? -> False\n","파라미터 features.41.bias     가 gradient 를 tracking 하나요? -> False\n","파라미터 features.43.weight   가 gradient 를 tracking 하나요? -> False\n","파라미터 features.43.bias     가 gradient 를 tracking 하나요? -> False\n","파라미터 features.44.weight   가 gradient 를 tracking 하나요? -> False\n","파라미터 features.44.bias     가 gradient 를 tracking 하나요? -> False\n","파라미터 features.46.weight   가 gradient 를 tracking 하나요? -> False\n","파라미터 features.46.bias     가 gradient 를 tracking 하나요? -> False\n","파라미터 features.47.weight   가 gradient 를 tracking 하나요? -> False\n","파라미터 features.47.bias     가 gradient 를 tracking 하나요? -> False\n","파라미터 features.49.weight   가 gradient 를 tracking 하나요? -> False\n","파라미터 features.49.bias     가 gradient 를 tracking 하나요? -> False\n","파라미터 features.50.weight   가 gradient 를 tracking 하나요? -> False\n","파라미터 features.50.bias     가 gradient 를 tracking 하나요? -> False\n","파라미터 classifier.0.weight  가 gradient 를 tracking 하나요? -> True\n","파라미터 classifier.0.bias    가 gradient 를 tracking 하나요? -> True\n","파라미터 classifier.3.weight  가 gradient 를 tracking 하나요? -> True\n","파라미터 classifier.3.bias    가 gradient 를 tracking 하나요? -> True\n","파라미터 classifier.6.weight  가 gradient 를 tracking 하나요? -> True\n","파라미터 classifier.6.bias    가 gradient 를 tracking 하나요? -> True\n"]}],"source":["# feature 파트만 freeze\n","model.features.requires_grad_(False) # self.feature 안에 있는 모든 것들을 한 번에 requires_grad_(False) 로 만듦. 다른 것은 그대로 True임.\n","for param, weight in model.named_parameters():\n","    print(f\"파라미터 {param:20} 가 gradient 를 tracking 하나요? -> {weight.requires_grad}\")"]},{"cell_type":"markdown","id":"LM4aPLqeUSg8","metadata":{"id":"LM4aPLqeUSg8"},"source":["#### Weight initialization \n"," - weight 초기화는 종종 모델의 성능에 critical 한 영향을 줍니다.\n"," - 하지만 만약 pretrained 모델을 사용한다면 pretrained 부분은 초기화를 하지 말고, 재정의한 task specific 파트만 초기화하여야 합니다."]},{"cell_type":"code","execution_count":11,"id":"I_5s0otKUSg8","metadata":{"id":"I_5s0otKUSg8"},"outputs":[],"source":["import torch.nn.init as init\n","\n","def initialize_weights(model):\n","    \"\"\"\n","    Xavier uniform 분포로 모든 weight 를 초기화합니다.\n","    더 많은 weight 초기화 방법은 다음 문서에서 참고해주세요. https://pytorch.org/docs/stable/nn.init.html\n","    \"\"\"\n","    for m in model.modules():\n","        if isinstance(m, nn.Conv2d):\n","            init.xavier_uniform_(m.weight.data) # 내가 알기로는 어떤 활성화함수를 쓰느냐에 따라, 초기화 하는 방법이 달라짐. 분포을 균등하게 만들어주기 위해\n","            if m.bias is not None:\n","                m.bias.data.zero_() # bias는 대부분 0으로 초기화하는 듯?\n","        elif isinstance(m, nn.BatchNorm2d):\n","            m.weight.data.fill_(1)\n","            m.bias.data.zero_()\n","        elif isinstance(m, nn.Linear):\n","            m.weight.data.normal_(0, 0.01)\n","            m.bias.data.zero_()"]},{"cell_type":"markdown","id":"mRDhT8vnUSg9","metadata":{"id":"mRDhT8vnUSg9"},"source":["#### pretrained 모델을 가져와 가장 앞단 layer 의 weight 분포를 봐봅시다"]},{"cell_type":"code","execution_count":17,"id":"GNghuOsYUSg9","metadata":{"id":"GNghuOsYUSg9"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","\n","model = vgg19_bn(pretrained=True)\n","\n","# Weight Initialization 이전 모델 feature 파트의 첫번째 weight 분포\n","plt.hist(model.features[0].weight.detach().numpy().reshape(-1)) # detach : Returns a new Tensor, detached from the current graph.\n","                                                                # gradient 전파가 안되는 텐서를 만듦\n","                                                                # reshape(-1) : 1차원으로 만듦\n","plt.show()"]},{"cell_type":"markdown","id":"yeAhmcpbUSg-","metadata":{"id":"yeAhmcpbUSg-"},"source":["#### weight 초기화 후 분포를 봐 봅시다\n"," - `xavier_uniform` 으로 초기화하여 웨이트들이 uniform 한 분포를 가지게 되었습니다."]},{"cell_type":"code","execution_count":18,"id":"ISYQG_TDUSg-","metadata":{"id":"ISYQG_TDUSg-"},"outputs":[{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAATSklEQVR4nO3df4xlZ33f8fcnXnAbAvE6Hraubbo2WhI5abJOpo6lFOTgBGw3wVCQsysECyFdaEEKSqTKQFuiqFEhDSFFtLaW4GBLYOzguLjB+bFxCSRVTTJrlmWNcbzr2GK3y+5gJ+Bi5Hbtb/+4Z9Tj8Yzn/pxZP3m/pKt7znN+fefcuZ8589xzz0lVIUlqy3dtdAGSpOkz3CWpQYa7JDXIcJekBhnuktSgTRtdAMBZZ51VW7du3egyJOlZZd++fd+oqrmVpp0S4b5161YWFhY2ugxJelZJ8tBq0+yWkaQGrRnuSc5L8tkkX0lyT5Jf7NrPTLI3yf3d8+auPUk+lORQkgNJfnTWP4Qk6amGOXI/CfxyVV0IXAK8PcmFwDXAnVW1DbizGwe4AtjWPXYD1069aknSM1oz3KvqWFXd3Q0/CtwLnANcBdzQzXYD8Opu+Crgxhq4CzgjydlTr1yStKqR+tyTbAUuAr4AbKmqY92krwNbuuFzgK/1FjvStS1f1+4kC0kWFhcXRyxbkvRMhg73JN8D3Aq8s6q+1Z9Wg6uPjXQFsqraU1XzVTU/N7fimTySpDENFe5JnsMg2D9eVb/XNR9f6m7pnk907UeB83qLn9u1SZLWyTBnywT4KHBvVf1mb9LtwK5ueBfw6V77G7uzZi4BvtnrvpEkrYNhvsT0E8AbgC8n2d+1vRt4H3BLkrcADwFXd9PuAK4EDgGPAW+easWSpDWtGe5V9edAVpl82QrzF/D2Cet6Vth6zWc2ZLsPvu+fbch2JT17+A1VSWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoNOidvsSXq6jfqSHPhFuRZ45C5JDTLcJalBhrskNchwl6QGGe6S1CDPlpHWsJFnrUjj8shdkhrkkbukv/Na/E6BR+6S1KBhbpB9fZITSQ722m5Osr97PLh0b9UkW5N8pzftulkWL0la2TDdMh8DPgzcuNRQVT+3NJzkA8A3e/Mfrqrt0ypQkjS6YW6Q/fkkW1ealiTA1cDLp1uWJGkSk/a5vxQ4XlX399rOT/LFJJ9L8tLVFkyyO8lCkoXFxcUJy5Ak9U0a7juBm3rjx4AXVdVFwC8Bn0jygpUWrKo9VTVfVfNzc3MTliFJ6hs73JNsAv45cPNSW1U9XlUPd8P7gMPASyYtUpI0mknOc/8p4KtVdWSpIckc8EhVPZHkAmAb8MCENeoUslHnA3t9cWk0w5wKeRPwP4HvT3IkyVu6STt4apcMwMuAA92pkZ8C3lZVj0yzYEnS2oY5W2bnKu1vWqHtVuDWycuSJE3Cb6hKUoMMd0lqkBcOexbyErSS1uKRuyQ1yHCXpAYZ7pLUoCb63O2DlqSn8shdkhpkuEtSg5rolpE0XXZ1Pvt55C5JDTLcJalBdsvoWcFuAmk0HrlLUoMMd0lqkOEuSQ0y3CWpQcPcZu/6JCeSHOy1/UqSo0n2d48re9PeleRQkvuSvHJWhUuSVjfMkfvHgMtXaP9gVW3vHncAJLmQwb1Vf7Bb5r8kOW1axUqShrNmuFfV54Fhb3J9FfDJqnq8qv4aOARcPEF9kqQxTNLn/o4kB7pum81d2znA13rzHOnanibJ7iQLSRYWFxcnKEOStNy44X4t8GJgO3AM+MCoK6iqPVU1X1Xzc3NzY5YhSVrJWOFeVcer6omqehL4CP+/6+UocF5v1nO7NknSOhor3JOc3Rt9DbB0Js3twI4kpyc5H9gG/MVkJUqSRrXmtWWS3ARcCpyV5AjwXuDSJNuBAh4E3gpQVfckuQX4CnASeHtVPTGb0iVJq1kz3Ktq5wrNH32G+X8N+LVJipIkTcZvqEpSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJatCa4Z7k+iQnkhzstf3HJF9NciDJbUnO6Nq3JvlOkv3d47pZFi9JWtkwR+4fAy5f1rYX+KGq+mHgr4B39aYdrqrt3eNt0ylTkjSKNcO9qj4PPLKs7Y+r6mQ3ehdw7gxqkySNaRp97j8P/EFv/PwkX0zyuSQvXW2hJLuTLCRZWFxcnEIZkqQlE4V7kvcAJ4GPd03HgBdV1UXALwGfSPKClZatqj1VNV9V83Nzc5OUIUlaZuxwT/Im4GeA11dVAVTV41X1cDe8DzgMvGQKdUqSRjBWuCe5HPjXwKuq6rFe+1yS07rhC4BtwAPTKFSSNLxNa82Q5CbgUuCsJEeA9zI4O+Z0YG8SgLu6M2NeBvxqkv8LPAm8raoeWXHFkqSZWTPcq2rnCs0fXWXeW4FbJy1KkjQZv6EqSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDRoq3JNcn+REkoO9tjOT7E1yf/e8uWtPkg8lOZTkQJIfnVXxkqSVDXvk/jHg8mVt1wB3VtU24M5uHOAKBjfG3gbsBq6dvExJ0iiGCveq+jyw/EbXVwE3dMM3AK/utd9YA3cBZyQ5exrFSpKGM0mf+5aqOtYNfx3Y0g2fA3ytN9+Rru0pkuxOspBkYXFxcYIyJEnLTeUD1aoqoEZcZk9VzVfV/Nzc3DTKkCR1Jgn340vdLd3zia79KHBeb75zuzZJ0jqZJNxvB3Z1w7uAT/fa39idNXMJ8M1e940kaR1sGmamJDcBlwJnJTkCvBd4H3BLkrcADwFXd7PfAVwJHAIeA9485ZolSWsYKtyraucqky5bYd4C3j5JUZKkyfgNVUlqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWrQUHdiWkmS7wdu7jVdAPw74AzgXwCLXfu7q+qOsSuUJI1s7HCvqvuA7QBJTgOOArcxuGfqB6vqN6ZSoSRpZNPqlrkMOFxVD01pfZKkCUwr3HcAN/XG35HkQJLrk2ye0jYkSUOaONyTPBd4FfC7XdO1wIsZdNkcAz6wynK7kywkWVhcXFxpFknSmKZx5H4FcHdVHQeoquNV9URVPQl8BLh4pYWqak9VzVfV/Nzc3BTKkCQtmUa476TXJZPk7N601wAHp7ANSdIIxj5bBiDJ84CfBt7aa/71JNuBAh5cNk2StA4mCveq+jbwfcva3jBRRZKkifkNVUlqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDZroNnsASR4EHgWeAE5W1XySM4Gbga0M7qN6dVX9zaTbkiQNZ1pH7j9ZVdurar4bvwa4s6q2AXd245KkdTKrbpmrgBu64RuAV89oO5KkFUwj3Av44yT7kuzu2rZU1bFu+OvAluULJdmdZCHJwuLi4hTKkCQtmbjPHfinVXU0yQuBvUm+2p9YVZWkli9UVXuAPQDz8/NPmy5JGt/ER+5VdbR7PgHcBlwMHE9yNkD3fGLS7UiShjdRuCd5XpLnLw0DrwAOArcDu7rZdgGfnmQ7kqTRTNotswW4LcnSuj5RVX+Y5C+BW5K8BXgIuHrC7UiSRjBRuFfVA8CPrND+MHDZJOuWJI3Pb6hKUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSg8YO9yTnJflskq8kuSfJL3btv5LkaJL93ePK6ZUrSRrGJLfZOwn8clXd3d0ke1+Svd20D1bVb0xeniRpHGOHe1UdA451w48muRc4Z1qFSZLGN5U+9yRbgYuAL3RN70hyIMn1STavsszuJAtJFhYXF6dRhiSpM3G4J/ke4FbgnVX1LeBa4MXAdgZH9h9Yabmq2lNV81U1Pzc3N2kZkqSeicI9yXMYBPvHq+r3AKrqeFU9UVVPAh8BLp68TEnSKCY5WybAR4F7q+o3e+1n92Z7DXBw/PIkSeOY5GyZnwDeAHw5yf6u7d3AziTbgQIeBN46UYWSpJFNcrbMnwNZYdId45cjSZoGv6EqSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBMwv3JJcnuS/JoSTXzGo7kqSnm0m4JzkN+M/AFcCFDG6afeEstiVJerpZHblfDByqqgeq6v8AnwSumtG2JEnLbJrRes8BvtYbPwL8eH+GJLuB3d3o/05y35jbOgv4xpjLzpJ1je5Urc26RmNdI8j7J6rrH602YVbhvqaq2gPsmXQ9SRaqan4KJU2VdY3uVK3NukZjXaOZVV2z6pY5CpzXGz+3a5MkrYNZhftfAtuSnJ/kucAO4PYZbUuStMxMumWq6mSSdwB/BJwGXF9V98xiW0yha2dGrGt0p2pt1jUa6xrNTOpKVc1ivZKkDeQ3VCWpQYa7JDXolA33JGcm2Zvk/u558yrz/WGSv03y+8vaz0/yhe7yBzd3H+yS5PRu/FA3feuM6trVzXN/kl1d2/OT7O89vpHkt7ppb0qy2Jv2C+tVV9f+p93lIpa2/8KufSP313cn+UySrya5J8n7evOPtb/WuizGM/28Sd7Vtd+X5JXDrnOWdSX56ST7kny5e355b5kVX9N1rG1rku/0tn9db5kf62o+lORDSbKOdb1+2fvwySTbu2kT77Mh6npZkruTnEzyumXTVnt/jr6/quqUfAC/DlzTDV8DvH+V+S4Dfhb4/WXttwA7uuHrgH/ZDf8r4LpueAdw87TrAs4EHuieN3fDm1eYbx/wsm74TcCHZ7m/nqku4E+B+RWW2bD9BXw38JPdPM8F/gy4Ytz9xeDD/cPABd36vgRcOMzPy+AyGl8CTgfO79Zz2jDrnHFdFwH/sBv+IeBob5kVX9N1rG0rcHCV9f4FcAkQ4A+WXtf1qGvZPP8YODytfTZkXVuBHwZuBF435Ptz5P11yh65M7hcwQ3d8A3Aq1eaqaruBB7tt3V/1V4OfGqF5fvr/RRw2YhHDcPU9Upgb1U9UlV/A+wFLl9W40uAFzIIrGmYSl1rrHdd91dVPVZVnwWowWUs7mbwnYlxDXNZjNV+3quAT1bV41X118Chbn3TuNTG2HVV1Rer6n917fcAfz/J6SNufya1rbbCJGcDL6iqu2qQXDeyyvt7Hera2S07LWvWVVUPVtUB4Mlly674Phh3f53K4b6lqo51w18Htoyw7PcBf1tVJ7vxIwwuiQC9SyN007/ZzT/Nula6/MI5y+ZZOpLon6702iQHknwqyXmMZhp1/U73r+i/7b0JTon9leQMBv+h3dlrHnV/DfO6rPbzrrbsMOucZV19rwXurqrHe20rvabrWdv5Sb6Y5HNJXtqb/8ga65x1XUt+DrhpWdsk+2yS34dn+h0beX9t2OUHAJL8CfAPVpj0nv5IVVWSdTtnc53q2gG8oTf+34CbqurxJG9lcMTx8v4CM67r9VV1NMnzgVu72m4cZsFZ768kmxi8AT9UVQ90zWvur79Lkvwg8H7gFb3msV/TKTkGvKiqHk7yY8B/7eo8JST5ceCxqjrYa97ofTY1GxruVfVTq01LcjzJ2VV1rPu35MQIq34YOCPJpu4vdv/yB0uXRjjShcb3dvNPs66jwKW98XMZ9OUtreNHgE1Vta+3zX4Nv82gr/opZllXVR3tnh9N8gkG/17eyCmwvxh8yeP+qvqt3jbX3F+rbGety2Ks9vM+07KTXmpjkrpIci5wG/DGqjq8tMAzvKbrUlv3X+njXQ37khwGXtLN3+9eW/d91tnBsqP2KeyzSS69str7YKz9dSp3y9wOLH1avAv49LALdr9UnwWWPonuL99f7+uA/76sa2Qadf0R8IokmzM4O+QVXduSnSz7peqCb8mrgHtHqGmiupJsSnJWV8dzgJ8Blo5mNnR/Jfn3DN6U7+wvMOb+GuayGKv9vLcDOzI4A+N8YBuDD7mmcamNsevquqs+w+BD6/+xNPMar+l61TaXwb0dSHIBg332QNdN960kl3TdHm9khPf3pHV19XwXcDW9/vYp7bNJfh9WfB+Mvb/W+sR1ox4M+sbuBO4H/gQ4s2ufB367N9+fAYvAdxj0Rb2ya7+AwZvvEPC7wOld+9/rxg910y+YUV0/323jEPDmZet4APiBZW3/gcEHYl9i8IfpB9arLuB5DM7cOdDV8J+A0zZ6fzE4QikGwb2/e/zCJPsLuBL4KwZnNLyna/tV4FVr/bwMupkOA/fRO1thpXWO8fs+Vl3AvwG+3ds/+xl8UL/qa7qOtb222/Z+Bh+G/2xvnfMMgvMw8GG6b8uvR13dtEuBu5atbyr7bIi6/gmDrPo2g/8k7lkrN8bZX15+QJIadCp3y0iSxmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAb9P0T0vmuDDX8SAAAAAElFTkSuQmCC","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["model = vgg19_bn(pretrained=True)\n","\n","# 모든 weight 를 initialize\n","initialize_weights(model.features) # 함수를 짜서 긱 layer의 특성에 맞게 초기화하는 방법을 달리 줌.\n","\n","# Weight Initialization 이후 모델 feature 파트의 첫번째 weight 분포\n","# (xavier) uniform 한 분포로 바뀐 것을 확인할 수 있습니다.\n","plt.hist(model.features[0].weight.detach().numpy().reshape(-1))\n","plt.show()"]},{"cell_type":"markdown","id":"fbqr7onnUSg_","metadata":{"id":"fbqr7onnUSg_"},"source":["#### task specific 한 부분만 초기화하엿습니다\n"," - feature extraction 파트는 초기화가 되지 않은 것은 확인할 수 있습니다."]},{"cell_type":"code","execution_count":19,"id":"kvlDANr6USg_","metadata":{"id":"kvlDANr6USg_"},"outputs":[{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAR00lEQVR4nO3dfYzc113v8ffnxiSlhVs78ZIG28UpWIWAQI1WaaAIVTWkSYrqINoqFSJuMTIVKU9FKi5IRCpCtPde3UAEBJnG1JGqtCU8xEBKMEmrCgmHbErz3JJtSGtbTrw0qaFUtAS+/DHHMHV2vQ+zO2P3vF/SaM7vnDPz+85o9JnfnvnNbKoKSVIf/tekC5AkjY+hL0kdMfQlqSOGviR1xNCXpI6sm3QBp7Nx48baunXrpMuQpLPK/fff/09VNTXf2Bkd+lu3bmVmZmbSZUjSWSXJZxcac3lHkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6ckZ/I1c6k23d8xcT2e+T73ndRParrw0e6UtSRwx9SeqIoS9JHTH0Jakjhr4kdWTR0E+yL8nxJA/PM/aLSSrJxradJDclmU3yYJJLh+buTPJ4u+xc3YchSVqKpRzpvx+48tTOJFuAK4DPDXVfBWxrl93AzW3u+cANwCuBy4AbkmwYpXBJ0vItGvpV9XHgmXmGbgTeCdRQ3w7g1ho4BKxPchHwWuBgVT1TVc8CB5nnjUSStLZWtKafZAdwtKoeOGVoE3B4aPtI61uoX5I0Rsv+Rm6SFwK/zGBpZ9Ul2c1gaYiXvvSla7ELSerWSo70vxW4GHggyZPAZuATSV4CHAW2DM3d3PoW6n+eqtpbVdNVNT01Ne8/c5ckrdCyQ7+qHqqqb6qqrVW1lcFSzaVV9RRwALiuncVzOXCiqo4BdwFXJNnQPsC9ovVJksZoKads3gb8LfDyJEeS7DrN9DuBJ4BZ4PeBnwaoqmeAXwPua5d3tz5J0hgtuqZfVW9eZHzrULuA6xeYtw/Yt8z6JEmryG/kSlJHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4uGfpJ9SY4neXio7/8m+VSSB5P8SZL1Q2PvSjKb5NNJXjvUf2Xrm02yZ/UfiiRpMUs50n8/cOUpfQeB76qq7wb+AXgXQJJLgGuB72y3+d0k5yQ5B/gd4CrgEuDNba4kaYwWDf2q+jjwzCl9f1VVz7XNQ8Dm1t4BfLCqvlxV/wjMApe1y2xVPVFVXwE+2OZKksZoNdb0fwL4SGtvAg4PjR1pfQv1P0+S3UlmkszMzc2tQnmSpJNGCv0kvwI8B3xgdcqBqtpbVdNVNT01NbVadytJAtat9IZJ3gL8MLC9qqp1HwW2DE3b3Po4Tb8kaUxWdKSf5ErgncDrq+pLQ0MHgGuTnJfkYmAb8HfAfcC2JBcnOZfBh70HRitdkrRcix7pJ7kNeDWwMckR4AYGZ+ucBxxMAnCoqt5WVY8k+TDwKINln+ur6j/a/bwduAs4B9hXVY+sweORJJ3GoqFfVW+ep/uW08z/deDX5+m/E7hzWdVJklaV38iVpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOrJo6CfZl+R4koeH+s5PcjDJ4+16Q+tPkpuSzCZ5MMmlQ7fZ2eY/nmTn2jwcSdLpLOVI//3Alaf07QHurqptwN1tG+AqYFu77AZuhsGbBHAD8ErgMuCGk28UkqTxWTT0q+rjwDOndO8A9rf2fuCaof5ba+AQsD7JRcBrgYNV9UxVPQsc5PlvJJKkNbbSNf0Lq+pYaz8FXNjam4DDQ/OOtL6F+p8nye4kM0lm5ubmVlieJGk+I3+QW1UF1CrUcvL+9lbVdFVNT01NrdbdSpJYeeg/3ZZtaNfHW/9RYMvQvM2tb6F+SdIYrTT0DwAnz8DZCdwx1H9dO4vncuBEWwa6C7giyYb2Ae4VrU+SNEbrFpuQ5Dbg1cDGJEcYnIXzHuDDSXYBnwXe1KbfCVwNzAJfAt4KUFXPJPk14L42791VdeqHw5KkNbZo6FfVmxcY2j7P3AKuX+B+9gH7llWdJGlV+Y1cSeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSMjhX6SX0jySJKHk9yW5AVJLk5yb5LZJB9Kcm6be17bnm3jW1fjAUiSlm7FoZ9kE/CzwHRVfRdwDnAt8F7gxqr6NuBZYFe7yS7g2dZ/Y5snSRqjUZd31gFfn2Qd8ELgGPAa4PY2vh+4prV3tG3a+PYkGXH/kqRlWHHoV9VR4P8Bn2MQ9ieA+4EvVNVzbdoRYFNrbwIOt9s+1+ZfcOr9JtmdZCbJzNzc3ErLkyTNY5TlnQ0Mjt4vBr4ZeBFw5agFVdXeqpququmpqalR706SNGSU5Z0fBP6xquaq6t+BPwZeBaxvyz0Am4GjrX0U2ALQxl8MfH6E/UuSlmmU0P8ccHmSF7a1+e3Ao8BHgTe0OTuBO1r7QNumjd9TVTXC/iVJyzTKmv69DD6Q/QTwULuvvcAvAe9IMstgzf6WdpNbgAta/zuAPSPULUlagXWLT1lYVd0A3HBK9xPAZfPM/TfgjaPsT5I0Gr+RK0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHVkpNBPsj7J7Uk+leSxJN+b5PwkB5M83q43tLlJclOS2SQPJrl0dR6CJGmpRj3S/y3gL6vq24HvAR4D9gB3V9U24O62DXAVsK1ddgM3j7hvSdIyrTj0k7wY+AHgFoCq+kpVfQHYAexv0/YD17T2DuDWGjgErE9y0YorlyQt2yhH+hcDc8AfJPn7JO9L8iLgwqo61uY8BVzY2puAw0O3P9L6vkqS3UlmkszMzc2NUJ4k6VSjhP464FLg5qp6BfCv/M9SDgBVVUAt506ram9VTVfV9NTU1AjlSZJONUroHwGOVNW9bft2Bm8CT59ctmnXx9v4UWDL0O03tz5J0pisOPSr6ingcJKXt67twKPAAWBn69sJ3NHaB4Dr2lk8lwMnhpaBJEljsG7E2/8M8IEk5wJPAG9l8Eby4SS7gM8Cb2pz7wSuBmaBL7W5kqQxGin0q+qTwPQ8Q9vnmVvA9aPsT5I0Gr+RK0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHVk5NBPck6Sv0/y52374iT3JplN8qH2T9NJcl7bnm3jW0fdtyRpeVbjSP/ngMeGtt8L3FhV3wY8C+xq/buAZ1v/jW2eJGmMRgr9JJuB1wHva9sBXgPc3qbsB65p7R1tmza+vc2XJI3JqEf6vwm8E/jPtn0B8IWqeq5tHwE2tfYm4DBAGz/R5n+VJLuTzCSZmZubG7E8SdKwFYd+kh8GjlfV/atYD1W1t6qmq2p6ampqNe9akrq3boTbvgp4fZKrgRcA/xv4LWB9knXtaH4zcLTNPwpsAY4kWQe8GPj8CPuXJC3Tio/0q+pdVbW5qrYC1wL3VNWPAR8F3tCm7QTuaO0DbZs2fk9V1Ur3L0lavrU4T/+XgHckmWWwZn9L678FuKD1vwPYswb7liSdxijLO/+tqj4GfKy1nwAum2fOvwFvXI39SZJWxm/kSlJHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR1Zcegn2ZLko0keTfJIkp9r/ecnOZjk8Xa9ofUnyU1JZpM8mOTS1XoQkqSlGeVI/zngF6vqEuBy4PoklwB7gLurahtwd9sGuArY1i67gZtH2LckaQVWHPpVdayqPtHa/wI8BmwCdgD727T9wDWtvQO4tQYOAeuTXLTiyiVJy7Yqa/pJtgKvAO4FLqyqY23oKeDC1t4EHB662ZHWJ0kak5FDP8k3AH8E/HxV/fPwWFUVUMu8v91JZpLMzM3NjVqeJGnISKGf5OsYBP4HquqPW/fTJ5dt2vXx1n8U2DJ0882t76tU1d6qmq6q6ampqVHKkySdYpSzdwLcAjxWVf9/aOgAsLO1dwJ3DPVf187iuRw4MbQMJEkag3Uj3PZVwI8DDyX5ZOv7ZeA9wIeT7AI+C7ypjd0JXA3MAl8C3jrCviVJK7Di0K+qvwGywPD2eeYXcP1K9ydJGp3fyJWkjoyyvCNN3NY9fzHpEqSzikf6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTf05fOMpP8HwJPvud1E9u3Voehr1XhPzORzg4u70hSR8Ye+kmuTPLpJLNJ9ox7/5LUs7Eu7yQ5B/gd4IeAI8B9SQ5U1aPjrONrmcssWkuTen35WcLqGfeR/mXAbFU9UVVfAT4I7BhzDZLUrXF/kLsJODy0fQR45fCEJLuB3W3zi0k+PabaTtoI/NOY97larH0yrH2N5b3zdp8VtS9grWv/loUGzrizd6pqL7B3UvtPMlNV05Pa/yisfTKsfTKsfWXGvbxzFNgytL259UmSxmDcoX8fsC3JxUnOBa4FDoy5Bknq1liXd6rquSRvB+4CzgH2VdUj46xhCSa2tLQKrH0yrH0yrH0FUlWT2rckacz8Rq4kdcTQl6SOdB/6Sd6Y5JEk/5lkwVOokjyZ5KEkn0wyM84aF7KM2s+4n75Icn6Sg0keb9cbFpj3H+05/2SSiX7ov9jzmOS8JB9q4/cm2Tr+Kue3hNrfkmRu6Ln+yUnUeaok+5IcT/LwAuNJclN7XA8muXTcNS5kCbW/OsmJoef8V8dSWFV1fQG+A3g58DFg+jTzngQ2Trre5dbO4APzzwAvA84FHgAuOQNq/z/AntbeA7x3gXlfnHStS30egZ8Gfq+1rwU+NOm6l1H7W4DfnnSt89T+A8ClwMMLjF8NfAQIcDlw76RrXkbtrwb+fNx1dX+kX1WPVdW4v/W7KpZY+5n60xc7gP2tvR+4ZoK1LMVSnsfhx3Q7sD1JxljjQs7U18CiqurjwDOnmbIDuLUGDgHrk1w0nupObwm1T0T3ob8MBfxVkvvbT0WcLeb76YtNE6pl2IVVday1nwIuXGDeC5LMJDmUZJJvDEt5Hv97TlU9B5wALhhLdae31NfAj7YlktuTbJln/Ex0pr6+l+p7kzyQ5CNJvnMcOzzjfoZhLST5a+Al8wz9SlXdscS7+f6qOprkm4CDST7V3snX1CrVPhGnq314o6oqyULnDn9Le95fBtyT5KGq+sxq1yr+DLitqr6c5KcY/MXymgnX9LXuEwxe319McjXwp8C2td5pF6FfVT+4CvdxtF0fT/InDP5kXvPQX4XaJ/bTF6erPcnTSS6qqmPtz/HjC9zHyef9iSQfA17BYH163JbyPJ6ccyTJOuDFwOfHU95pLVp7VQ3X+T4Gn7mcDc7an3apqn8eat+Z5HeTbKyqNf0ROZd3liDJi5J848k2cAUw7yfyZ6Az9acvDgA7W3sn8Ly/WpJsSHJea28EXgVM6n8vLOV5HH5MbwDuqfaJ3YQtWvsp6+CvBx4bY32jOABc187iuRw4MbRseEZL8pKTn/kkuYxBHq/9QcKkP+Ge9AX4EQbrgF8Gngbuav3fDNzZ2i9jcMbDA8AjDJZWzora2/bVwD8wOEI+U2q/ALgbeBz4a+D81j8NvK+1vw94qD3vDwG7Jlzz855H4N3A61v7BcAfArPA3wEvm/TzvIzaf6O9th8APgp8+6RrbnXdBhwD/r291ncBbwPe1sbD4B8zfaa9RhY8A+8MrP3tQ8/5IeD7xlGXP8MgSR1xeUeSOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI78F3ziWQ9TiQOmAAAAAElFTkSuQmCC","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["model = vgg19_bn(pretrained=True)\n","\n","# Classifier 부분만 initialize\n","initialize_weights(model.classifier)\n","\n","# Weight Initialization 이후 모델 feature 파트의 첫번째 weight 분포\n","# classifier 부분만 xavier uniform 으로 초기화해서 feature 파트는 uniform 한 분포를 가지지 않는 것을 확인할 수 있습니다.\n","plt.hist(model.features[0].weight.detach().numpy().reshape(-1)) \n","plt.show()"]},{"cell_type":"markdown","id":"o5rYLwDKUSg_","metadata":{"id":"o5rYLwDKUSg_"},"source":["## Appendix (optional)"]},{"cell_type":"markdown","id":"DYtGOREKUShA","metadata":{"id":"DYtGOREKUShA"},"source":["### SOTA (State Of The Art)  모델을 리서치 하는 방법\n","- timm\n","- paper with code"]},{"cell_type":"markdown","id":"2IlmlHvDUShA","metadata":{"id":"2IlmlHvDUShA"},"source":["## timm (pyTorch IMage Models)\n","\n","PyTorch Image Models (timm) is a collection of image models, layers, utilities, optimizers, schedulers, data-loaders / augmentations, and reference training / validation scripts that aim to pull together a wide variety of SOTA models with ability to reproduce ImageNet training results.\n","\n","#### References\n","https://github.com/rwightman/pytorch-image-models#introduction\n","\n","https://fastai.github.io/timmdocs/\n","\n","https://rwightman.github.io/pytorch-image-models/"]},{"cell_type":"code","execution_count":20,"id":"qLTgGr7EUShA","metadata":{"id":"qLTgGr7EUShA"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting timm\n","  Downloading timm-0.5.4-py3-none-any.whl (431 kB)\n","\u001b[K     |████████████████████████████████| 431 kB 19.6 MB/s eta 0:00:01\n","\u001b[?25hRequirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.8/site-packages (from timm) (1.7.1)\n","Requirement already satisfied: torchvision in /opt/conda/lib/python3.8/site-packages (from timm) (0.8.2)\n","Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.8/site-packages (from torch>=1.4->timm) (3.7.4.3)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from torch>=1.4->timm) (1.19.2)\n","Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.8/site-packages (from torchvision->timm) (8.1.0)\n","Installing collected packages: timm\n","Successfully installed timm-0.5.4\n"]}],"source":["!pip install timm"]},{"cell_type":"markdown","id":"yF6B71PxUShA","metadata":{"id":"yF6B71PxUShA"},"source":["#### Timm 을 사용하여 pretrained 모델 불러오기"]},{"cell_type":"code","execution_count":21,"id":"R2dV1z-1UShB","metadata":{"id":"R2dV1z-1UShB"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/mobilenetv3_large_100_ra-f55367f5.pth\" to /opt/ml/.cache/torch/hub/checkpoints/mobilenetv3_large_100_ra-f55367f5.pth\n"]},{"data":{"text/plain":["MobileNetV3(\n","  (conv_stem): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (act1): Hardswish()\n","  (blocks): Sequential(\n","    (0): Sequential(\n","      (0): DepthwiseSeparableConv(\n","        (conv_dw): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n","        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (se): Identity()\n","        (conv_pw): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act2): Identity()\n","      )\n","    )\n","    (1): Sequential(\n","      (0): InvertedResidual(\n","        (conv_pw): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv_dw): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act2): ReLU(inplace=True)\n","        (se): Identity()\n","        (conv_pwl): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): InvertedResidual(\n","        (conv_pw): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv_dw): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n","        (bn2): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act2): ReLU(inplace=True)\n","        (se): Identity()\n","        (conv_pwl): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (2): Sequential(\n","      (0): InvertedResidual(\n","        (conv_pw): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv_dw): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n","        (bn2): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act2): ReLU(inplace=True)\n","        (se): SqueezeExcite(\n","          (conv_reduce): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n","          (act1): ReLU(inplace=True)\n","          (conv_expand): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n","          (gate): Hardsigmoid()\n","        )\n","        (conv_pwl): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): InvertedResidual(\n","        (conv_pw): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv_dw): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n","        (bn2): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act2): ReLU(inplace=True)\n","        (se): SqueezeExcite(\n","          (conv_reduce): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n","          (act1): ReLU(inplace=True)\n","          (conv_expand): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n","          (gate): Hardsigmoid()\n","        )\n","        (conv_pwl): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): InvertedResidual(\n","        (conv_pw): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv_dw): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n","        (bn2): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act2): ReLU(inplace=True)\n","        (se): SqueezeExcite(\n","          (conv_reduce): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n","          (act1): ReLU(inplace=True)\n","          (conv_expand): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n","          (gate): Hardsigmoid()\n","        )\n","        (conv_pwl): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (3): Sequential(\n","      (0): InvertedResidual(\n","        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): Hardswish()\n","        (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n","        (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act2): Hardswish()\n","        (se): Identity()\n","        (conv_pwl): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): InvertedResidual(\n","        (conv_pw): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): Hardswish()\n","        (conv_dw): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n","        (bn2): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act2): Hardswish()\n","        (se): Identity()\n","        (conv_pwl): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): InvertedResidual(\n","        (conv_pw): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): Hardswish()\n","        (conv_dw): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n","        (bn2): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act2): Hardswish()\n","        (se): Identity()\n","        (conv_pwl): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (3): InvertedResidual(\n","        (conv_pw): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): Hardswish()\n","        (conv_dw): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n","        (bn2): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act2): Hardswish()\n","        (se): Identity()\n","        (conv_pwl): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (4): Sequential(\n","      (0): InvertedResidual(\n","        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): Hardswish()\n","        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n","        (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act2): Hardswish()\n","        (se): SqueezeExcite(\n","          (conv_reduce): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n","          (act1): ReLU(inplace=True)\n","          (conv_expand): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n","          (gate): Hardsigmoid()\n","        )\n","        (conv_pwl): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): InvertedResidual(\n","        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): Hardswish()\n","        (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n","        (bn2): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act2): Hardswish()\n","        (se): SqueezeExcite(\n","          (conv_reduce): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n","          (act1): ReLU(inplace=True)\n","          (conv_expand): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n","          (gate): Hardsigmoid()\n","        )\n","        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (5): Sequential(\n","      (0): InvertedResidual(\n","        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): Hardswish()\n","        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n","        (bn2): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act2): Hardswish()\n","        (se): SqueezeExcite(\n","          (conv_reduce): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n","          (act1): ReLU(inplace=True)\n","          (conv_expand): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n","          (gate): Hardsigmoid()\n","        )\n","        (conv_pwl): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): InvertedResidual(\n","        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): Hardswish()\n","        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n","        (bn2): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act2): Hardswish()\n","        (se): SqueezeExcite(\n","          (conv_reduce): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n","          (act1): ReLU(inplace=True)\n","          (conv_expand): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n","          (gate): Hardsigmoid()\n","        )\n","        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): InvertedResidual(\n","        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): Hardswish()\n","        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n","        (bn2): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act2): Hardswish()\n","        (se): SqueezeExcite(\n","          (conv_reduce): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n","          (act1): ReLU(inplace=True)\n","          (conv_expand): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n","          (gate): Hardsigmoid()\n","        )\n","        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (6): Sequential(\n","      (0): ConvBnAct(\n","        (conv): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): Hardswish()\n","      )\n","    )\n","  )\n","  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Identity())\n","  (conv_head): Conv2d(960, 1280, kernel_size=(1, 1), stride=(1, 1))\n","  (act2): Hardswish()\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (classifier): Linear(in_features=1280, out_features=1000, bias=True)\n",")"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["import timm\n","\n","m = timm.create_model('mobilenetv3_large_100', pretrained=True)\n","m.eval() # 평가 모드. 업데이트를 하거나 이러한 것들을 하지 않음."]},{"cell_type":"markdown","id":"NxpGBf1HUShB","metadata":{"id":"NxpGBf1HUShB"},"source":["#### Timm 에서 사용가능한 pretrained 모델 목록"]},{"cell_type":"code","execution_count":22,"id":"MnZYn5SlUShB","metadata":{"id":"MnZYn5SlUShB"},"outputs":[{"name":"stdout","output_type":"stream","text":["['adv_inception_v3',\n"," 'bat_resnext26ts',\n"," 'beit_base_patch16_224',\n"," 'beit_base_patch16_224_in22k',\n"," 'beit_base_patch16_384',\n"," 'beit_large_patch16_224',\n"," 'beit_large_patch16_224_in22k',\n"," 'beit_large_patch16_384',\n"," 'beit_large_patch16_512',\n"," 'botnet26t_256',\n"," 'cait_m36_384',\n"," 'cait_m48_448',\n"," 'cait_s24_224',\n"," 'cait_s24_384',\n"," 'cait_s36_384',\n"," 'cait_xs24_384',\n"," 'cait_xxs24_224',\n"," 'cait_xxs24_384',\n"," 'cait_xxs36_224',\n"," 'cait_xxs36_384',\n"," 'coat_lite_mini',\n"," 'coat_lite_small',\n"," 'coat_lite_tiny',\n"," 'coat_mini',\n"," 'coat_tiny',\n"," 'convit_base',\n"," 'convit_small',\n"," 'convit_tiny',\n"," 'convmixer_768_32',\n"," 'convmixer_1024_20_ks9_p14',\n"," 'convmixer_1536_20',\n"," 'convnext_base',\n"," 'convnext_base_384_in22ft1k',\n"," 'convnext_base_in22ft1k',\n"," 'convnext_base_in22k',\n"," 'convnext_large',\n"," 'convnext_large_384_in22ft1k',\n"," 'convnext_large_in22ft1k',\n"," 'convnext_large_in22k',\n"," 'convnext_small',\n"," 'convnext_tiny',\n"," 'convnext_xlarge_384_in22ft1k',\n"," 'convnext_xlarge_in22ft1k',\n"," 'convnext_xlarge_in22k',\n"," 'crossvit_9_240',\n"," 'crossvit_9_dagger_240',\n"," 'crossvit_15_240',\n"," 'crossvit_15_dagger_240',\n"," 'crossvit_15_dagger_408',\n"," 'crossvit_18_240',\n"," 'crossvit_18_dagger_240',\n"," 'crossvit_18_dagger_408',\n"," 'crossvit_base_240',\n"," 'crossvit_small_240',\n"," 'crossvit_tiny_240',\n"," 'cspdarknet53',\n"," 'cspresnet50',\n"," 'cspresnext50',\n"," 'deit_base_distilled_patch16_224',\n"," 'deit_base_distilled_patch16_384',\n"," 'deit_base_patch16_224',\n"," 'deit_base_patch16_384',\n"," 'deit_small_distilled_patch16_224',\n"," 'deit_small_patch16_224',\n"," 'deit_tiny_distilled_patch16_224',\n"," 'deit_tiny_patch16_224',\n"," 'densenet121',\n"," 'densenet161',\n"," 'densenet169',\n"," 'densenet201',\n"," 'densenetblur121d',\n"," 'dla34',\n"," 'dla46_c',\n"," 'dla46x_c',\n"," 'dla60',\n"," 'dla60_res2net',\n"," 'dla60_res2next',\n"," 'dla60x',\n"," 'dla60x_c',\n"," 'dla102',\n"," 'dla102x',\n"," 'dla102x2',\n"," 'dla169',\n"," 'dm_nfnet_f0',\n"," 'dm_nfnet_f1',\n"," 'dm_nfnet_f2',\n"," 'dm_nfnet_f3',\n"," 'dm_nfnet_f4',\n"," 'dm_nfnet_f5',\n"," 'dm_nfnet_f6',\n"," 'dpn68',\n"," 'dpn68b',\n"," 'dpn92',\n"," 'dpn98',\n"," 'dpn107',\n"," 'dpn131',\n"," 'eca_botnext26ts_256',\n"," 'eca_halonext26ts',\n"," 'eca_nfnet_l0',\n"," 'eca_nfnet_l1',\n"," 'eca_nfnet_l2',\n"," 'eca_resnet33ts',\n"," 'eca_resnext26ts',\n"," 'ecaresnet26t',\n"," 'ecaresnet50d',\n"," 'ecaresnet50d_pruned',\n"," 'ecaresnet50t',\n"," 'ecaresnet101d',\n"," 'ecaresnet101d_pruned',\n"," 'ecaresnet269d',\n"," 'ecaresnetlight',\n"," 'efficientnet_b0',\n"," 'efficientnet_b1',\n"," 'efficientnet_b1_pruned',\n"," 'efficientnet_b2',\n"," 'efficientnet_b2_pruned',\n"," 'efficientnet_b3',\n"," 'efficientnet_b3_pruned',\n"," 'efficientnet_b4',\n"," 'efficientnet_el',\n"," 'efficientnet_el_pruned',\n"," 'efficientnet_em',\n"," 'efficientnet_es',\n"," 'efficientnet_es_pruned',\n"," 'efficientnet_lite0',\n"," 'efficientnetv2_rw_m',\n"," 'efficientnetv2_rw_s',\n"," 'efficientnetv2_rw_t',\n"," 'ens_adv_inception_resnet_v2',\n"," 'ese_vovnet19b_dw',\n"," 'ese_vovnet39b',\n"," 'fbnetc_100',\n"," 'fbnetv3_b',\n"," 'fbnetv3_d',\n"," 'fbnetv3_g',\n"," 'gc_efficientnetv2_rw_t',\n"," 'gcresnet33ts',\n"," 'gcresnet50t',\n"," 'gcresnext26ts',\n"," 'gcresnext50ts',\n"," 'gernet_l',\n"," 'gernet_m',\n"," 'gernet_s',\n"," 'ghostnet_100',\n"," 'gluon_inception_v3',\n"," 'gluon_resnet18_v1b',\n"," 'gluon_resnet34_v1b',\n"," 'gluon_resnet50_v1b',\n"," 'gluon_resnet50_v1c',\n"," 'gluon_resnet50_v1d',\n"," 'gluon_resnet50_v1s',\n"," 'gluon_resnet101_v1b',\n"," 'gluon_resnet101_v1c',\n"," 'gluon_resnet101_v1d',\n"," 'gluon_resnet101_v1s',\n"," 'gluon_resnet152_v1b',\n"," 'gluon_resnet152_v1c',\n"," 'gluon_resnet152_v1d',\n"," 'gluon_resnet152_v1s',\n"," 'gluon_resnext50_32x4d',\n"," 'gluon_resnext101_32x4d',\n"," 'gluon_resnext101_64x4d',\n"," 'gluon_senet154',\n"," 'gluon_seresnext50_32x4d',\n"," 'gluon_seresnext101_32x4d',\n"," 'gluon_seresnext101_64x4d',\n"," 'gluon_xception65',\n"," 'gmixer_24_224',\n"," 'gmlp_s16_224',\n"," 'halo2botnet50ts_256',\n"," 'halonet26t',\n"," 'halonet50ts',\n"," 'haloregnetz_b',\n"," 'hardcorenas_a',\n"," 'hardcorenas_b',\n"," 'hardcorenas_c',\n"," 'hardcorenas_d',\n"," 'hardcorenas_e',\n"," 'hardcorenas_f',\n"," 'hrnet_w18',\n"," 'hrnet_w18_small',\n"," 'hrnet_w18_small_v2',\n"," 'hrnet_w30',\n"," 'hrnet_w32',\n"," 'hrnet_w40',\n"," 'hrnet_w44',\n"," 'hrnet_w48',\n"," 'hrnet_w64',\n"," 'ig_resnext101_32x8d',\n"," 'ig_resnext101_32x16d',\n"," 'ig_resnext101_32x32d',\n"," 'ig_resnext101_32x48d',\n"," 'inception_resnet_v2',\n"," 'inception_v3',\n"," 'inception_v4',\n"," 'jx_nest_base',\n"," 'jx_nest_small',\n"," 'jx_nest_tiny',\n"," 'lambda_resnet26rpt_256',\n"," 'lambda_resnet26t',\n"," 'lambda_resnet50ts',\n"," 'lamhalobotnet50ts_256',\n"," 'lcnet_050',\n"," 'lcnet_075',\n"," 'lcnet_100',\n"," 'legacy_senet154',\n"," 'legacy_seresnet18',\n"," 'legacy_seresnet34',\n"," 'legacy_seresnet50',\n"," 'legacy_seresnet101',\n"," 'legacy_seresnet152',\n"," 'legacy_seresnext26_32x4d',\n"," 'legacy_seresnext50_32x4d',\n"," 'legacy_seresnext101_32x4d',\n"," 'levit_128',\n"," 'levit_128s',\n"," 'levit_192',\n"," 'levit_256',\n"," 'levit_384',\n"," 'mixer_b16_224',\n"," 'mixer_b16_224_in21k',\n"," 'mixer_b16_224_miil',\n"," 'mixer_b16_224_miil_in21k',\n"," 'mixer_l16_224',\n"," 'mixer_l16_224_in21k',\n"," 'mixnet_l',\n"," 'mixnet_m',\n"," 'mixnet_s',\n"," 'mixnet_xl',\n"," 'mnasnet_100',\n"," 'mnasnet_small',\n"," 'mobilenetv2_050',\n"," 'mobilenetv2_100',\n"," 'mobilenetv2_110d',\n"," 'mobilenetv2_120d',\n"," 'mobilenetv2_140',\n"," 'mobilenetv3_large_100',\n"," 'mobilenetv3_large_100_miil',\n"," 'mobilenetv3_large_100_miil_in21k',\n"," 'mobilenetv3_rw',\n"," 'nasnetalarge',\n"," 'nf_regnet_b1',\n"," 'nf_resnet50',\n"," 'nfnet_l0',\n"," 'pit_b_224',\n"," 'pit_b_distilled_224',\n"," 'pit_s_224',\n"," 'pit_s_distilled_224',\n"," 'pit_ti_224',\n"," 'pit_ti_distilled_224',\n"," 'pit_xs_224',\n"," 'pit_xs_distilled_224',\n"," 'pnasnet5large',\n"," 'regnetx_002',\n"," 'regnetx_004',\n"," 'regnetx_006',\n"," 'regnetx_008',\n"," 'regnetx_016',\n"," 'regnetx_032',\n"," 'regnetx_040',\n"," 'regnetx_064',\n"," 'regnetx_080',\n"," 'regnetx_120',\n"," 'regnetx_160',\n"," 'regnetx_320',\n"," 'regnety_002',\n"," 'regnety_004',\n"," 'regnety_006',\n"," 'regnety_008',\n"," 'regnety_016',\n"," 'regnety_032',\n"," 'regnety_040',\n"," 'regnety_064',\n"," 'regnety_080',\n"," 'regnety_120',\n"," 'regnety_160',\n"," 'regnety_320',\n"," 'regnetz_b16',\n"," 'regnetz_c16',\n"," 'regnetz_d8',\n"," 'regnetz_d32',\n"," 'regnetz_e8',\n"," 'repvgg_a2',\n"," 'repvgg_b0',\n"," 'repvgg_b1',\n"," 'repvgg_b1g4',\n"," 'repvgg_b2',\n"," 'repvgg_b2g4',\n"," 'repvgg_b3',\n"," 'repvgg_b3g4',\n"," 'res2net50_14w_8s',\n"," 'res2net50_26w_4s',\n"," 'res2net50_26w_6s',\n"," 'res2net50_26w_8s',\n"," 'res2net50_48w_2s',\n"," 'res2net101_26w_4s',\n"," 'res2next50',\n"," 'resmlp_12_224',\n"," 'resmlp_12_224_dino',\n"," 'resmlp_12_distilled_224',\n"," 'resmlp_24_224',\n"," 'resmlp_24_224_dino',\n"," 'resmlp_24_distilled_224',\n"," 'resmlp_36_224',\n"," 'resmlp_36_distilled_224',\n"," 'resmlp_big_24_224',\n"," 'resmlp_big_24_224_in22ft1k',\n"," 'resmlp_big_24_distilled_224',\n"," 'resnest14d',\n"," 'resnest26d',\n"," 'resnest50d',\n"," 'resnest50d_1s4x24d',\n"," 'resnest50d_4s2x40d',\n"," 'resnest101e',\n"," 'resnest200e',\n"," 'resnest269e',\n"," 'resnet18',\n"," 'resnet18d',\n"," 'resnet26',\n"," 'resnet26d',\n"," 'resnet26t',\n"," 'resnet32ts',\n"," 'resnet33ts',\n"," 'resnet34',\n"," 'resnet34d',\n"," 'resnet50',\n"," 'resnet50_gn',\n"," 'resnet50d',\n"," 'resnet51q',\n"," 'resnet61q',\n"," 'resnet101',\n"," 'resnet101d',\n"," 'resnet152',\n"," 'resnet152d',\n"," 'resnet200d',\n"," 'resnetblur50',\n"," 'resnetrs50',\n"," 'resnetrs101',\n"," 'resnetrs152',\n"," 'resnetrs200',\n"," 'resnetrs270',\n"," 'resnetrs350',\n"," 'resnetrs420',\n"," 'resnetv2_50',\n"," 'resnetv2_50x1_bit_distilled',\n"," 'resnetv2_50x1_bitm',\n"," 'resnetv2_50x1_bitm_in21k',\n"," 'resnetv2_50x3_bitm',\n"," 'resnetv2_50x3_bitm_in21k',\n"," 'resnetv2_101',\n"," 'resnetv2_101x1_bitm',\n"," 'resnetv2_101x1_bitm_in21k',\n"," 'resnetv2_101x3_bitm',\n"," 'resnetv2_101x3_bitm_in21k',\n"," 'resnetv2_152x2_bit_teacher',\n"," 'resnetv2_152x2_bit_teacher_384',\n"," 'resnetv2_152x2_bitm',\n"," 'resnetv2_152x2_bitm_in21k',\n"," 'resnetv2_152x4_bitm',\n"," 'resnetv2_152x4_bitm_in21k',\n"," 'resnext26ts',\n"," 'resnext50_32x4d',\n"," 'resnext50d_32x4d',\n"," 'resnext101_32x8d',\n"," 'rexnet_100',\n"," 'rexnet_130',\n"," 'rexnet_150',\n"," 'rexnet_200',\n"," 'sebotnet33ts_256',\n"," 'sehalonet33ts',\n"," 'selecsls42b',\n"," 'selecsls60',\n"," 'selecsls60b',\n"," 'semnasnet_075',\n"," 'semnasnet_100',\n"," 'seresnet33ts',\n"," 'seresnet50',\n"," 'seresnet152d',\n"," 'seresnext26d_32x4d',\n"," 'seresnext26t_32x4d',\n"," 'seresnext26ts',\n"," 'seresnext50_32x4d',\n"," 'skresnet18',\n"," 'skresnet34',\n"," 'skresnext50_32x4d',\n"," 'spnasnet_100',\n"," 'ssl_resnet18',\n"," 'ssl_resnet50',\n"," 'ssl_resnext50_32x4d',\n"," 'ssl_resnext101_32x4d',\n"," 'ssl_resnext101_32x8d',\n"," 'ssl_resnext101_32x16d',\n"," 'swin_base_patch4_window7_224',\n"," 'swin_base_patch4_window7_224_in22k',\n"," 'swin_base_patch4_window12_384',\n"," 'swin_base_patch4_window12_384_in22k',\n"," 'swin_large_patch4_window7_224',\n"," 'swin_large_patch4_window7_224_in22k',\n"," 'swin_large_patch4_window12_384',\n"," 'swin_large_patch4_window12_384_in22k',\n"," 'swin_small_patch4_window7_224',\n"," 'swin_tiny_patch4_window7_224',\n"," 'swsl_resnet18',\n"," 'swsl_resnet50',\n"," 'swsl_resnext50_32x4d',\n"," 'swsl_resnext101_32x4d',\n"," 'swsl_resnext101_32x8d',\n"," 'swsl_resnext101_32x16d',\n"," 'tf_efficientnet_b0',\n"," 'tf_efficientnet_b0_ap',\n"," 'tf_efficientnet_b0_ns',\n"," 'tf_efficientnet_b1',\n"," 'tf_efficientnet_b1_ap',\n"," 'tf_efficientnet_b1_ns',\n"," 'tf_efficientnet_b2',\n"," 'tf_efficientnet_b2_ap',\n"," 'tf_efficientnet_b2_ns',\n"," 'tf_efficientnet_b3',\n"," 'tf_efficientnet_b3_ap',\n"," 'tf_efficientnet_b3_ns',\n"," 'tf_efficientnet_b4',\n"," 'tf_efficientnet_b4_ap',\n"," 'tf_efficientnet_b4_ns',\n"," 'tf_efficientnet_b5',\n"," 'tf_efficientnet_b5_ap',\n"," 'tf_efficientnet_b5_ns',\n"," 'tf_efficientnet_b6',\n"," 'tf_efficientnet_b6_ap',\n"," 'tf_efficientnet_b6_ns',\n"," 'tf_efficientnet_b7',\n"," 'tf_efficientnet_b7_ap',\n"," 'tf_efficientnet_b7_ns',\n"," 'tf_efficientnet_b8',\n"," 'tf_efficientnet_b8_ap',\n"," 'tf_efficientnet_cc_b0_4e',\n"," 'tf_efficientnet_cc_b0_8e',\n"," 'tf_efficientnet_cc_b1_8e',\n"," 'tf_efficientnet_el',\n"," 'tf_efficientnet_em',\n"," 'tf_efficientnet_es',\n"," 'tf_efficientnet_l2_ns',\n"," 'tf_efficientnet_l2_ns_475',\n"," 'tf_efficientnet_lite0',\n"," 'tf_efficientnet_lite1',\n"," 'tf_efficientnet_lite2',\n"," 'tf_efficientnet_lite3',\n"," 'tf_efficientnet_lite4',\n"," 'tf_efficientnetv2_b0',\n"," 'tf_efficientnetv2_b1',\n"," 'tf_efficientnetv2_b2',\n"," 'tf_efficientnetv2_b3',\n"," 'tf_efficientnetv2_l',\n"," 'tf_efficientnetv2_l_in21ft1k',\n"," 'tf_efficientnetv2_l_in21k',\n"," 'tf_efficientnetv2_m',\n"," 'tf_efficientnetv2_m_in21ft1k',\n"," 'tf_efficientnetv2_m_in21k',\n"," 'tf_efficientnetv2_s',\n"," 'tf_efficientnetv2_s_in21ft1k',\n"," 'tf_efficientnetv2_s_in21k',\n"," 'tf_efficientnetv2_xl_in21ft1k',\n"," 'tf_efficientnetv2_xl_in21k',\n"," 'tf_inception_v3',\n"," 'tf_mixnet_l',\n"," 'tf_mixnet_m',\n"," 'tf_mixnet_s',\n"," 'tf_mobilenetv3_large_075',\n"," 'tf_mobilenetv3_large_100',\n"," 'tf_mobilenetv3_large_minimal_100',\n"," 'tf_mobilenetv3_small_075',\n"," 'tf_mobilenetv3_small_100',\n"," 'tf_mobilenetv3_small_minimal_100',\n"," 'tinynet_a',\n"," 'tinynet_b',\n"," 'tinynet_c',\n"," 'tinynet_d',\n"," 'tinynet_e',\n"," 'tnt_s_patch16_224',\n"," 'tresnet_l',\n"," 'tresnet_l_448',\n"," 'tresnet_m',\n"," 'tresnet_m_448',\n"," 'tresnet_m_miil_in21k',\n"," 'tresnet_xl',\n"," 'tresnet_xl_448',\n"," 'tv_densenet121',\n"," 'tv_resnet34',\n"," 'tv_resnet50',\n"," 'tv_resnet101',\n"," 'tv_resnet152',\n"," 'tv_resnext50_32x4d',\n"," 'twins_pcpvt_base',\n"," 'twins_pcpvt_large',\n"," 'twins_pcpvt_small',\n"," 'twins_svt_base',\n"," 'twins_svt_large',\n"," 'twins_svt_small',\n"," 'vgg11',\n"," 'vgg11_bn',\n"," 'vgg13',\n"," 'vgg13_bn',\n"," 'vgg16',\n"," 'vgg16_bn',\n"," 'vgg19',\n"," 'vgg19_bn',\n"," 'visformer_small',\n"," 'vit_base_patch8_224',\n"," 'vit_base_patch8_224_in21k',\n"," 'vit_base_patch16_224',\n"," 'vit_base_patch16_224_in21k',\n"," 'vit_base_patch16_224_miil',\n"," 'vit_base_patch16_224_miil_in21k',\n"," 'vit_base_patch16_384',\n"," 'vit_base_patch16_sam_224',\n"," 'vit_base_patch32_224',\n"," 'vit_base_patch32_224_in21k',\n"," 'vit_base_patch32_384',\n"," 'vit_base_patch32_sam_224',\n"," 'vit_base_r50_s16_224_in21k',\n"," 'vit_base_r50_s16_384',\n"," 'vit_huge_patch14_224_in21k',\n"," 'vit_large_patch16_224',\n"," 'vit_large_patch16_224_in21k',\n"," 'vit_large_patch16_384',\n"," 'vit_large_patch32_224_in21k',\n"," 'vit_large_patch32_384',\n"," 'vit_large_r50_s32_224',\n"," 'vit_large_r50_s32_224_in21k',\n"," 'vit_large_r50_s32_384',\n"," 'vit_small_patch16_224',\n"," 'vit_small_patch16_224_in21k',\n"," 'vit_small_patch16_384',\n"," 'vit_small_patch32_224',\n"," 'vit_small_patch32_224_in21k',\n"," 'vit_small_patch32_384',\n"," 'vit_small_r26_s32_224',\n"," 'vit_small_r26_s32_224_in21k',\n"," 'vit_small_r26_s32_384',\n"," 'vit_tiny_patch16_224',\n"," 'vit_tiny_patch16_224_in21k',\n"," 'vit_tiny_patch16_384',\n"," 'vit_tiny_r_s16_p8_224',\n"," 'vit_tiny_r_s16_p8_224_in21k',\n"," 'vit_tiny_r_s16_p8_384',\n"," 'wide_resnet50_2',\n"," 'wide_resnet101_2',\n"," 'xception',\n"," 'xception41',\n"," 'xception65',\n"," 'xception71',\n"," 'xcit_large_24_p8_224',\n"," 'xcit_large_24_p8_224_dist',\n"," 'xcit_large_24_p8_384_dist',\n"," 'xcit_large_24_p16_224',\n"," 'xcit_large_24_p16_224_dist',\n"," 'xcit_large_24_p16_384_dist',\n"," 'xcit_medium_24_p8_224',\n"," 'xcit_medium_24_p8_224_dist',\n"," 'xcit_medium_24_p8_384_dist',\n"," 'xcit_medium_24_p16_224',\n"," 'xcit_medium_24_p16_224_dist',\n"," 'xcit_medium_24_p16_384_dist',\n"," 'xcit_nano_12_p8_224',\n"," 'xcit_nano_12_p8_224_dist',\n"," 'xcit_nano_12_p8_384_dist',\n"," 'xcit_nano_12_p16_224',\n"," 'xcit_nano_12_p16_224_dist',\n"," 'xcit_nano_12_p16_384_dist',\n"," 'xcit_small_12_p8_224',\n"," 'xcit_small_12_p8_224_dist',\n"," 'xcit_small_12_p8_384_dist',\n"," 'xcit_small_12_p16_224',\n"," 'xcit_small_12_p16_224_dist',\n"," 'xcit_small_12_p16_384_dist',\n"," 'xcit_small_24_p8_224',\n"," 'xcit_small_24_p8_224_dist',\n"," 'xcit_small_24_p8_384_dist',\n"," 'xcit_small_24_p16_224',\n"," 'xcit_small_24_p16_224_dist',\n"," 'xcit_small_24_p16_384_dist',\n"," 'xcit_tiny_12_p8_224',\n"," 'xcit_tiny_12_p8_224_dist',\n"," 'xcit_tiny_12_p8_384_dist',\n"," 'xcit_tiny_12_p16_224',\n"," 'xcit_tiny_12_p16_224_dist',\n"," 'xcit_tiny_12_p16_384_dist',\n"," 'xcit_tiny_24_p8_224',\n"," 'xcit_tiny_24_p8_224_dist',\n"," 'xcit_tiny_24_p8_384_dist',\n"," 'xcit_tiny_24_p16_224',\n"," 'xcit_tiny_24_p16_224_dist',\n"," 'xcit_tiny_24_p16_384_dist']\n"]}],"source":["import timm\n","from pprint import pprint\n","model_names = timm.list_models(pretrained=True)\n","pprint(model_names)"]},{"cell_type":"markdown","id":"GuK012_QUShC","metadata":{"id":"GuK012_QUShC"},"source":["#### 다음과 같은 방법을 통해서 원하는 모델을 찾는 것도 가능합니다"]},{"cell_type":"code","execution_count":24,"id":"8q11NdteUShC","metadata":{"id":"8q11NdteUShC"},"outputs":[{"name":"stdout","output_type":"stream","text":["['bat_resnext26ts',\n"," 'cspresnet50',\n"," 'cspresnet50d',\n"," 'cspresnet50w',\n"," 'cspresnext50',\n"," 'cspresnext50_iabn',\n"," 'eca_resnet33ts',\n"," 'eca_resnext26ts',\n"," 'ecaresnet26t',\n"," 'ecaresnet50d',\n"," 'ecaresnet50d_pruned',\n"," 'ecaresnet50t',\n"," 'ecaresnet101d',\n"," 'ecaresnet101d_pruned',\n"," 'ecaresnet200d',\n"," 'ecaresnet269d',\n"," 'ecaresnetlight',\n"," 'ecaresnext26t_32x4d',\n"," 'ecaresnext50t_32x4d',\n"," 'ens_adv_inception_resnet_v2',\n"," 'gcresnet33ts',\n"," 'gcresnet50t',\n"," 'gcresnext26ts',\n"," 'gcresnext50ts',\n"," 'gluon_resnet18_v1b',\n"," 'gluon_resnet34_v1b',\n"," 'gluon_resnet50_v1b',\n"," 'gluon_resnet50_v1c',\n"," 'gluon_resnet50_v1d',\n"," 'gluon_resnet50_v1s',\n"," 'gluon_resnet101_v1b',\n"," 'gluon_resnet101_v1c',\n"," 'gluon_resnet101_v1d',\n"," 'gluon_resnet101_v1s',\n"," 'gluon_resnet152_v1b',\n"," 'gluon_resnet152_v1c',\n"," 'gluon_resnet152_v1d',\n"," 'gluon_resnet152_v1s',\n"," 'gluon_resnext50_32x4d',\n"," 'gluon_resnext101_32x4d',\n"," 'gluon_resnext101_64x4d',\n"," 'gluon_seresnext50_32x4d',\n"," 'gluon_seresnext101_32x4d',\n"," 'gluon_seresnext101_64x4d',\n"," 'ig_resnext101_32x8d',\n"," 'ig_resnext101_32x16d',\n"," 'ig_resnext101_32x32d',\n"," 'ig_resnext101_32x48d',\n"," 'inception_resnet_v2',\n"," 'lambda_resnet26rpt_256',\n"," 'lambda_resnet26t',\n"," 'lambda_resnet50ts',\n"," 'legacy_seresnet18',\n"," 'legacy_seresnet34',\n"," 'legacy_seresnet50',\n"," 'legacy_seresnet101',\n"," 'legacy_seresnet152',\n"," 'legacy_seresnext26_32x4d',\n"," 'legacy_seresnext50_32x4d',\n"," 'legacy_seresnext101_32x4d',\n"," 'nf_ecaresnet26',\n"," 'nf_ecaresnet50',\n"," 'nf_ecaresnet101',\n"," 'nf_resnet26',\n"," 'nf_resnet50',\n"," 'nf_resnet101',\n"," 'nf_seresnet26',\n"," 'nf_seresnet50',\n"," 'nf_seresnet101',\n"," 'resnest14d',\n"," 'resnest26d',\n"," 'resnest50d',\n"," 'resnest50d_1s4x24d',\n"," 'resnest50d_4s2x40d',\n"," 'resnest101e',\n"," 'resnest200e',\n"," 'resnest269e',\n"," 'resnet18',\n"," 'resnet18d',\n"," 'resnet26',\n"," 'resnet26d',\n"," 'resnet26t',\n"," 'resnet32ts',\n"," 'resnet33ts',\n"," 'resnet34',\n"," 'resnet34d',\n"," 'resnet50',\n"," 'resnet50_gn',\n"," 'resnet50d',\n"," 'resnet50t',\n"," 'resnet51q',\n"," 'resnet61q',\n"," 'resnet101',\n"," 'resnet101d',\n"," 'resnet152',\n"," 'resnet152d',\n"," 'resnet200',\n"," 'resnet200d',\n"," 'resnetblur18',\n"," 'resnetblur50',\n"," 'resnetrs50',\n"," 'resnetrs101',\n"," 'resnetrs152',\n"," 'resnetrs200',\n"," 'resnetrs270',\n"," 'resnetrs350',\n"," 'resnetrs420',\n"," 'resnetv2_50',\n"," 'resnetv2_50d',\n"," 'resnetv2_50d_evob',\n"," 'resnetv2_50d_evos',\n"," 'resnetv2_50d_gn',\n"," 'resnetv2_50t',\n"," 'resnetv2_50x1_bit_distilled',\n"," 'resnetv2_50x1_bitm',\n"," 'resnetv2_50x1_bitm_in21k',\n"," 'resnetv2_50x3_bitm',\n"," 'resnetv2_50x3_bitm_in21k',\n"," 'resnetv2_101',\n"," 'resnetv2_101d',\n"," 'resnetv2_101x1_bitm',\n"," 'resnetv2_101x1_bitm_in21k',\n"," 'resnetv2_101x3_bitm',\n"," 'resnetv2_101x3_bitm_in21k',\n"," 'resnetv2_152',\n"," 'resnetv2_152d',\n"," 'resnetv2_152x2_bit_teacher',\n"," 'resnetv2_152x2_bit_teacher_384',\n"," 'resnetv2_152x2_bitm',\n"," 'resnetv2_152x2_bitm_in21k',\n"," 'resnetv2_152x4_bitm',\n"," 'resnetv2_152x4_bitm_in21k',\n"," 'resnext26ts',\n"," 'resnext50_32x4d',\n"," 'resnext50d_32x4d',\n"," 'resnext101_32x4d',\n"," 'resnext101_32x8d',\n"," 'resnext101_64x4d',\n"," 'seresnet18',\n"," 'seresnet33ts',\n"," 'seresnet34',\n"," 'seresnet50',\n"," 'seresnet50t',\n"," 'seresnet101',\n"," 'seresnet152',\n"," 'seresnet152d',\n"," 'seresnet200d',\n"," 'seresnet269d',\n"," 'seresnext26d_32x4d',\n"," 'seresnext26t_32x4d',\n"," 'seresnext26tn_32x4d',\n"," 'seresnext26ts',\n"," 'seresnext50_32x4d',\n"," 'seresnext101_32x4d',\n"," 'seresnext101_32x8d',\n"," 'skresnet18',\n"," 'skresnet34',\n"," 'skresnet50',\n"," 'skresnet50d',\n"," 'skresnext50_32x4d',\n"," 'ssl_resnet18',\n"," 'ssl_resnet50',\n"," 'ssl_resnext50_32x4d',\n"," 'ssl_resnext101_32x4d',\n"," 'ssl_resnext101_32x8d',\n"," 'ssl_resnext101_32x16d',\n"," 'swsl_resnet18',\n"," 'swsl_resnet50',\n"," 'swsl_resnext50_32x4d',\n"," 'swsl_resnext101_32x4d',\n"," 'swsl_resnext101_32x8d',\n"," 'swsl_resnext101_32x16d',\n"," 'tresnet_l',\n"," 'tresnet_l_448',\n"," 'tresnet_m',\n"," 'tresnet_m_448',\n"," 'tresnet_m_miil_in21k',\n"," 'tresnet_xl',\n"," 'tresnet_xl_448',\n"," 'tv_resnet34',\n"," 'tv_resnet50',\n"," 'tv_resnet101',\n"," 'tv_resnet152',\n"," 'tv_resnext50_32x4d',\n"," 'vit_base_resnet26d_224',\n"," 'vit_base_resnet50_224_in21k',\n"," 'vit_base_resnet50_384',\n"," 'vit_base_resnet50d_224',\n"," 'vit_small_resnet26d_224',\n"," 'vit_small_resnet50d_s16_224',\n"," 'wide_resnet50_2',\n"," 'wide_resnet101_2']\n"]}],"source":["import timm\n","from pprint import pprint\n","model_names = timm.list_models('*resne*t*') # 정규표현식과 비슷한 듯?\n","pprint(model_names)"]},{"cell_type":"markdown","id":"_3W3me_bUShC","metadata":{"id":"_3W3me_bUShC"},"source":["## Paper with code\n"," - https://paperswithcode.com/task/image-classification\n"," - 다양한 태스크와 데이터셋에 대한 다양한 모델들의 성능을 벤치마킹해주는 웹서비스입니다.\n"," - 해당 서비스를 통해 각 모델들의 성능 비교뿐 아니라 논문과 구현 코드로 forwarding 도 가능합니다."]},{"cell_type":"markdown","id":"f26c9788","metadata":{"id":"f26c9788"},"source":["## 레이어 직접 쌓아보기"]},{"cell_type":"markdown","id":"bb19115f","metadata":{"id":"bb19115f"},"source":["![python image2](https://cphinf.pstatic.net/mooc/20210813_264/1628827925318KzHFu_JPEG/mceclip0.jpg)"]},{"cell_type":"markdown","id":"52e7d899","metadata":{"id":"52e7d899"},"source":["해당 모델 아키텍쳐는 향후 배우시게 될 Object Detection 쪽에서 하나의 큰 계보라 할 수 있는 yolo 의 backbone 으로 많이 사용하는 Darknet53 입니다\n","\n","Darknet53 은 ResidualBlock 을 해상도를 줄여가며(receptive field 를 늘려가며) 쌓은 구조를 가지고 있습니다. \n","> receptive field 는 출력 레이어의 뉴런 하나에 영향을 미치는 입력 뉴런들의 공간 크기이다.\n","\n","마지막 FC 레이어를 제외하고는 Feature Extraction Layer 로도 다양하게 활용할 수 있습니다."]},{"cell_type":"code","execution_count":25,"id":"52d900a7","metadata":{"id":"52d900a7"},"outputs":[],"source":["import torch\n","from torch import nn\n","\n","def conv_batch(in_num, out_num, kernel_size=3, padding=1, stride=1):\n","    return nn.Sequential(\n","        nn.Conv2d(in_num, out_num, kernel_size=kernel_size, stride=stride, padding=padding, bias=False),\n","        nn.BatchNorm2d(out_num),\n","        nn.LeakyReLU()) # ReLU와 비슷한데 x < 0 에서 모두 0이 아닌 약간의 음수 값(a, 상수 값에 따라 다름)들을 가지게 되는?\n","\n","\n","# Residual block\n","class DarkResidualBlock(nn.Module):\n","    def __init__(self, in_channels):\n","        super(DarkResidualBlock, self).__init__()\n","\n","        reduced_channels = int(in_channels/2) # 채널을 절반으로 줄임\n","\n","        self.layer1 = conv_batch(in_channels, reduced_channels, kernel_size=1, padding=0)\n","        self.layer2 = conv_batch(reduced_channels, in_channels)\n","\n","    def forward(self, x):\n","        residual = x\n","\n","        out = self.layer1(x)\n","        out = self.layer2(out)\n","        out += residual\n","        return out\n","\n","\n","class Darknet53(nn.Module):\n","    def __init__(self, block, num_classes):\n","        super(Darknet53, self).__init__()\n","\n","        self.num_classes = num_classes\n","\n","        self.features = nn.Sequential(\n","            conv_batch(3, 32),\n","            conv_batch(32, 64, stride=2),\n","            self.make_layer(block, in_channels=64, num_blocks=1),\n","            conv_batch(64, 128, stride=2),\n","            self.make_layer(block, in_channels=128, num_blocks=2),\n","            conv_batch(128, 256, stride=2),\n","            self.make_layer(block, in_channels=256, num_blocks=8), \n","            conv_batch(256, 512, stride=2),\n","            self.make_layer(block, in_channels=512, num_blocks=8),\n","            conv_batch(512, 1024, stride=2),\n","            self.make_layer(block, in_channels=1024, num_blocks=4),\n","        )\n","        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1)) # The number of output features is equal to the number of input planes\n","                                                            # target output size of 1x1\n","        self.classifier = nn.Linear(1024, self.num_classes)\n","\n","    def forward(self, x):\n","        out = self.features(x)\n","        out = self.global_avg_pool(out)\n","        out = out.view(-1, 1024)\n","        out = self.fc(out) # fully connected layer\n","\n","        return out\n","\n","    def make_layer(self, block, in_channels, num_blocks):\n","        layers = []\n","        for i in range(0, num_blocks):\n","            layers.append(block(in_channels)) # block은 아마도 residual block를 의미하는 듯\n","        return nn.Sequential(*layers) # *(asterisk)으로 값을 unpackin?\n","\n","\n","def darknet53(num_classes):\n","    return Darknet53(DarkResidualBlock, num_classes) # 여기서 block을 residual block으로 지정함"]},{"cell_type":"code","execution_count":29,"id":"7881dc94","metadata":{"id":"7881dc94","outputId":"bba77f2d-74e6-425a-b94d-9bdf6b3499a6"},"outputs":[{"data":{"text/plain":["Darknet53(\n","  (features): Sequential(\n","    (0): Sequential(\n","      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): LeakyReLU(negative_slope=0.01)\n","    )\n","    (1): Sequential(\n","      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): LeakyReLU(negative_slope=0.01)\n","    )\n","    (2): Sequential(\n","      (0): DarkResidualBlock(\n","        (layer1): Sequential(\n","          (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","        (layer2): Sequential(\n","          (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","      )\n","    )\n","    (3): Sequential(\n","      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): LeakyReLU(negative_slope=0.01)\n","    )\n","    (4): Sequential(\n","      (0): DarkResidualBlock(\n","        (layer1): Sequential(\n","          (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","        (layer2): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","      )\n","      (1): DarkResidualBlock(\n","        (layer1): Sequential(\n","          (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","        (layer2): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","      )\n","    )\n","    (5): Sequential(\n","      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): LeakyReLU(negative_slope=0.01)\n","    )\n","    (6): Sequential(\n","      (0): DarkResidualBlock(\n","        (layer1): Sequential(\n","          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","        (layer2): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","      )\n","      (1): DarkResidualBlock(\n","        (layer1): Sequential(\n","          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","        (layer2): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","      )\n","      (2): DarkResidualBlock(\n","        (layer1): Sequential(\n","          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","        (layer2): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","      )\n","      (3): DarkResidualBlock(\n","        (layer1): Sequential(\n","          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","        (layer2): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","      )\n","      (4): DarkResidualBlock(\n","        (layer1): Sequential(\n","          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","        (layer2): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","      )\n","      (5): DarkResidualBlock(\n","        (layer1): Sequential(\n","          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","        (layer2): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","      )\n","      (6): DarkResidualBlock(\n","        (layer1): Sequential(\n","          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","        (layer2): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","      )\n","      (7): DarkResidualBlock(\n","        (layer1): Sequential(\n","          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","        (layer2): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","      )\n","    )\n","    (7): Sequential(\n","      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): LeakyReLU(negative_slope=0.01)\n","    )\n","    (8): Sequential(\n","      (0): DarkResidualBlock(\n","        (layer1): Sequential(\n","          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","        (layer2): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","      )\n","      (1): DarkResidualBlock(\n","        (layer1): Sequential(\n","          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","        (layer2): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","      )\n","      (2): DarkResidualBlock(\n","        (layer1): Sequential(\n","          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","        (layer2): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","      )\n","      (3): DarkResidualBlock(\n","        (layer1): Sequential(\n","          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","        (layer2): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","      )\n","      (4): DarkResidualBlock(\n","        (layer1): Sequential(\n","          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","        (layer2): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","      )\n","      (5): DarkResidualBlock(\n","        (layer1): Sequential(\n","          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","        (layer2): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","      )\n","      (6): DarkResidualBlock(\n","        (layer1): Sequential(\n","          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","        (layer2): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","      )\n","      (7): DarkResidualBlock(\n","        (layer1): Sequential(\n","          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","        (layer2): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","      )\n","    )\n","    (9): Sequential(\n","      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): LeakyReLU(negative_slope=0.01)\n","    )\n","    (10): Sequential(\n","      (0): DarkResidualBlock(\n","        (layer1): Sequential(\n","          (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","        (layer2): Sequential(\n","          (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","      )\n","      (1): DarkResidualBlock(\n","        (layer1): Sequential(\n","          (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","        (layer2): Sequential(\n","          (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","      )\n","      (2): DarkResidualBlock(\n","        (layer1): Sequential(\n","          (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","        (layer2): Sequential(\n","          (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","      )\n","      (3): DarkResidualBlock(\n","        (layer1): Sequential(\n","          (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","        (layer2): Sequential(\n","          (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","      )\n","    )\n","  )\n","  (global_avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (classifier): Linear(in_features=1024, out_features=18, bias=True)\n",")"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["net = darknet53(num_classes=18)\n","net"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"6_Pretrained Model (정답).ipynb의 사본","provenance":[{"file_id":"13po17as09Aepva_nuJ9D-XykFhjPmqt4","timestamp":1645694970658}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":5}
