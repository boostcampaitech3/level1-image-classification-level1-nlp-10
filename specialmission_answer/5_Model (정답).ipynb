{"cells":[{"cell_type":"markdown","id":"UmDju1hmS-__","metadata":{"id":"UmDju1hmS-__"},"source":["## Lesson 5 - Model\n"," - 이번 실습 자료에서는 강의시간에 다루었던 파이토치 모델을 정의하는 방법에 대해 실습하겠습니다.\n"," - 파이토치 모델은 기본적으로 `nn.Module` 클래스를 상속하여 사용합니다.\n","     - [공식문서](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)에 따르면 `nn.Module` 은 다음과 같은 기능을 합니다\n","     ```\n","     Base class for all neural network modules.\n","     Your models should also subclass this class.\n","     Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes:\n","     ```"]},{"cell_type":"code","execution_count":1,"id":"zCROkRzlS-_7","metadata":{"id":"zCROkRzlS-_7"},"outputs":[],"source":["from pprint import pprint\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":10,"id":"toANDtC5S_AA","metadata":{"id":"toANDtC5S_AA"},"outputs":[],"source":["class Model(nn.Module):\n","    def __init__(self):\n","        super(Model, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3, bias=True)\n","        self.bn1 = nn.BatchNorm2d(num_features=3)\n","        self.conv2 = nn.Conv2d(in_channels=3, out_channels=5, kernel_size=3, bias=False)\n","\n","    def forward(self, x):\n","        x = F.relu(self.bn1(self.conv1(x)))\n","        return F.relu(self.conv2(x))"]},{"cell_type":"code","execution_count":11,"id":"uWxGW2iyS_AB","metadata":{"id":"uWxGW2iyS_AB"},"outputs":[{"data":{"text/plain":["Model(\n","  (conv1): Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1))\n","  (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv2): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",")"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["model = Model()\n","model # __repr__ 에 의해 작성되는 내용이 출력됨"]},{"cell_type":"markdown","id":"NtmySw1gS_AC","metadata":{"id":"NtmySw1gS_AC"},"source":["### 모델 디버깅\n"," - 파이토치 모델들은 다음과 같읕 방법들을 통해 파라미터를 눈으로 확인할 수 있습니다."]},{"cell_type":"code","execution_count":9,"id":"sX8A26RhS_AD","metadata":{"id":"sX8A26RhS_AD","scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["conv1.weight         - size: torch.Size([3, 1, 3, 3])\n","Parameter containing:\n","tensor([[[[-0.0737,  0.2374, -0.2765],\n","          [ 0.2147, -0.0392,  0.3004],\n","          [-0.1745, -0.1124, -0.2730]]],\n","\n","\n","        [[[-0.3279, -0.2294, -0.0094],\n","          [ 0.0700, -0.2474,  0.0075],\n","          [-0.0640,  0.2778,  0.0220]]],\n","\n","\n","        [[[-0.0055,  0.2793,  0.0202],\n","          [ 0.1964,  0.0872, -0.2789],\n","          [-0.2538, -0.1388, -0.0156]]]], requires_grad=True)\n","----------------------------------------------------------------------------------------------------\n","\n","conv1.bias           - size: torch.Size([3])\n","Parameter containing:\n","tensor([ 0.0577,  0.1554, -0.1626], requires_grad=True)\n","----------------------------------------------------------------------------------------------------\n","\n","bn1.weight           - size: torch.Size([3])\n","Parameter containing:\n","tensor([1., 1., 1.], requires_grad=True)\n","----------------------------------------------------------------------------------------------------\n","\n","bn1.bias             - size: torch.Size([3])\n","Parameter containing:\n","tensor([0., 0., 0.], requires_grad=True)\n","----------------------------------------------------------------------------------------------------\n","\n","conv2.weight         - size: torch.Size([5, 3, 3, 3])\n","Parameter containing:\n","tensor([[[[ 0.0377, -0.0774,  0.0368],\n","          [ 0.1022, -0.1883, -0.1213],\n","          [-0.1665, -0.0059,  0.1302]],\n","\n","         [[ 0.0868, -0.0345,  0.1187],\n","          [ 0.1587,  0.0133,  0.1552],\n","          [-0.1252, -0.1296, -0.1679]],\n","\n","         [[ 0.0874, -0.0559, -0.1009],\n","          [ 0.0676, -0.1233,  0.1548],\n","          [-0.1074,  0.1465,  0.1524]]],\n","\n","\n","        [[[-0.0342, -0.1547,  0.1236],\n","          [ 0.0540,  0.0524, -0.0182],\n","          [ 0.1005,  0.0270, -0.1824]],\n","\n","         [[ 0.1626,  0.0678,  0.0951],\n","          [ 0.0484, -0.0076,  0.1841],\n","          [ 0.1867, -0.1197, -0.0340]],\n","\n","         [[-0.1605,  0.1440, -0.1041],\n","          [ 0.1526,  0.0700,  0.1819],\n","          [ 0.0178,  0.0519,  0.1784]]],\n","\n","\n","        [[[ 0.1421,  0.0984, -0.0709],\n","          [-0.0431, -0.1046,  0.1055],\n","          [-0.1172, -0.0184,  0.0655]],\n","\n","         [[-0.0811,  0.1688,  0.1908],\n","          [-0.1895,  0.1752,  0.0468],\n","          [-0.1247,  0.0985, -0.1690]],\n","\n","         [[-0.0058,  0.1559, -0.1307],\n","          [-0.0724,  0.0127,  0.1628],\n","          [-0.0178, -0.0155, -0.1094]]],\n","\n","\n","        [[[-0.1054,  0.1125,  0.1072],\n","          [ 0.0508,  0.0399,  0.0937],\n","          [-0.1896,  0.0003, -0.1039]],\n","\n","         [[ 0.1271, -0.0096,  0.0980],\n","          [-0.1671, -0.0173, -0.0608],\n","          [ 0.0367,  0.1609, -0.0955]],\n","\n","         [[-0.0211,  0.0298, -0.1282],\n","          [ 0.1525,  0.0405, -0.0597],\n","          [-0.0203,  0.1053,  0.1661]]],\n","\n","\n","        [[[ 0.0671, -0.1008, -0.1095],\n","          [ 0.1762, -0.0748,  0.0872],\n","          [-0.0519,  0.1059, -0.1021]],\n","\n","         [[-0.0841,  0.0176,  0.0696],\n","          [ 0.1259,  0.1491, -0.0992],\n","          [ 0.1006,  0.1407, -0.0955]],\n","\n","         [[-0.1736,  0.1073,  0.1608],\n","          [-0.0957, -0.0152,  0.1091],\n","          [-0.1307, -0.1388,  0.0448]]]], requires_grad=True)\n","----------------------------------------------------------------------------------------------------\n","\n"]}],"source":["# 1. named_parameters() 를 이용하는 방식\n","for param, weight in model.named_parameters():\n","    print(f\"{param:20} - size: {weight.size()}\")\n","    print(weight)\n","    print(\"-\" * 100)\n","    print()\n","\n","#conv2.weight, bias는 출력이 안되는 건가?"]},{"cell_type":"code","execution_count":12,"id":"RGOd8u6NS_AD","metadata":{"id":"RGOd8u6NS_AD"},"outputs":[{"name":"stdout","output_type":"stream","text":["Parameter containing:\n","tensor([[[[ 0.3268, -0.1501,  0.1997],\n","          [-0.2453,  0.2992,  0.0743],\n","          [ 0.0536,  0.1946, -0.2259]]],\n","\n","\n","        [[[ 0.1911,  0.1731, -0.1467],\n","          [ 0.1870, -0.1161, -0.0766],\n","          [-0.1820, -0.1233, -0.1634]]],\n","\n","\n","        [[[ 0.2597,  0.0606, -0.1687],\n","          [ 0.0036, -0.2400, -0.0288],\n","          [-0.0100,  0.0519, -0.1070]]]], requires_grad=True)\n","Parameter containing:\n","tensor([0.1194, 0.0729, 0.2093], requires_grad=True)\n"]}],"source":["# 2. 멤버 변수를 이용하여 직접 access 하는 방법\n","print(model.conv1.weight)\n","print(model.conv1.bias)"]},{"cell_type":"markdown","id":"PV5CYMXRS_AE","metadata":{"id":"PV5CYMXRS_AE"},"source":["### 학습된 모델 저장하기\n"," - `torch.save(model.state_dict(), save_path)`"]},{"cell_type":"code","execution_count":14,"id":"Cq8GYbN1S_AF","metadata":{"id":"Cq8GYbN1S_AF"},"outputs":[{"name":"stdout","output_type":"stream","text":["./runs/best.pth 폴더에 모델이 성공적으로 저장되었습니다.\n","해당 폴더의 파일 리스트: ['best.pth']\n"]}],"source":["import os\n","\n","save_folder = \"./runs/\"\n","save_path = os.path.join(save_folder, \"best.pth\")   # ./runs/best.pth\n","os.makedirs(save_folder, exist_ok=True)  \n","\n","torch.save(model.state_dict(), save_path) # state_dict() : Returns a dictionary containing a whole state of the module\n","                                          # save() : Saves an object to a disk file\n","print(f\"{save_path} 폴더에 모델이 성공적으로 저장되었습니다.\")\n","print(f\"해당 폴더의 파일 리스트: {os.listdir(save_folder)}\")"]},{"cell_type":"markdown","id":"BqwVdTsKS_AF","metadata":{"id":"BqwVdTsKS_AF"},"source":["### 저장된 모델 불러오기\n"," - model.load_state_dict(torch.load(save_path))"]},{"cell_type":"code","execution_count":15,"id":"bZ4UN19tS_AG","metadata":{"id":"bZ4UN19tS_AG"},"outputs":[{"name":"stdout","output_type":"stream","text":["./runs/best.pth 에서 성공적으로 모델을 load 하였습니다.\n"]}],"source":["new_model = Model()\n","new_model.load_state_dict(torch.load(save_path))\n","# load() : Loads an object saved with :func:`torch.save` from a file\n","# load_state_dict() : Copies parameters and buffers from :attr:`state_dict` into this module and its descendants.\n","print(f\"{save_path} 에서 성공적으로 모델을 load 하였습니다.\")"]},{"cell_type":"markdown","id":"WZn5x9SdS_AG","metadata":{"id":"WZn5x9SdS_AG"},"source":["#### 저장된 모델이 잘 불러와졌는지 확인해봅시다"]},{"cell_type":"code","execution_count":16,"id":"qRYRythjS_AH","metadata":{"id":"qRYRythjS_AH"},"outputs":[{"name":"stdout","output_type":"stream","text":["파라미터 conv1.weight    에 대하여 trained 모델과 load 된 모델의 값이 같나요? -> True\n","파라미터 conv1.bias      에 대하여 trained 모델과 load 된 모델의 값이 같나요? -> True\n","파라미터 bn1.weight      에 대하여 trained 모델과 load 된 모델의 값이 같나요? -> True\n","파라미터 bn1.bias        에 대하여 trained 모델과 load 된 모델의 값이 같나요? -> True\n","파라미터 conv2.weight    에 대하여 trained 모델과 load 된 모델의 값이 같나요? -> True\n"]}],"source":["for (name, trained_weight), (_, saved_weight) in zip(model.named_parameters(), new_model.named_parameters()):\n","    is_equal = torch.equal(trained_weight, saved_weight)\n","    print(f\"파라미터 {name:15} 에 대하여 trained 모델과 load 된 모델의 값이 같나요? -> {is_equal}\")"]},{"cell_type":"markdown","id":"z9JD_kYqS_AH","metadata":{"id":"z9JD_kYqS_AH"},"source":["#### state_dict() 이 무엇인가요?\n"," - 모델의 저장과 로딩에 `state_dict()` 을 사용하는데, 기능이 무엇인가요?\n"," - 기본적으로 위에서 살펴본 `.named_parameters()` 와 매우 유사합니다\n"," - model parameter 를 Key 로 가지고, model weights 를 Value 로 가지는 파이썬 딕셔너리일 뿐입니다. \n","   (정확한 Type 은 파이썬 내장 라이브러리 collections.OrderDict 입니다)"]},{"cell_type":"code","execution_count":19,"id":"0yKFEBJTS_AH","metadata":{"id":"0yKFEBJTS_AH","scrolled":false},"outputs":[{"name":"stdout","output_type":"stream","text":["파라미터 네임 conv1.weight              / 사이즈: torch.Size([3, 1, 3, 3])\n","tensor([[[[ 0.3268, -0.1501,  0.1997],\n","          [-0.2453,  0.2992,  0.0743],\n","          [ 0.0536,  0.1946, -0.2259]]],\n","\n","\n","        [[[ 0.1911,  0.1731, -0.1467],\n","          [ 0.1870, -0.1161, -0.0766],\n","          [-0.1820, -0.1233, -0.1634]]],\n","\n","\n","        [[[ 0.2597,  0.0606, -0.1687],\n","          [ 0.0036, -0.2400, -0.0288],\n","          [-0.0100,  0.0519, -0.1070]]]])\n","----------------------------------------------------------------------------------------------------\n","\n","파라미터 네임 conv1.bias                / 사이즈: torch.Size([3])\n","tensor([0.1194, 0.0729, 0.2093])\n","----------------------------------------------------------------------------------------------------\n","\n","파라미터 네임 bn1.weight                / 사이즈: torch.Size([3])\n","tensor([1., 1., 1.])\n","----------------------------------------------------------------------------------------------------\n","\n","파라미터 네임 bn1.bias                  / 사이즈: torch.Size([3])\n","tensor([0., 0., 0.])\n","----------------------------------------------------------------------------------------------------\n","\n","파라미터 네임 bn1.running_mean          / 사이즈: torch.Size([3])\n","tensor([0., 0., 0.])\n","----------------------------------------------------------------------------------------------------\n","\n","파라미터 네임 bn1.running_var           / 사이즈: torch.Size([3])\n","tensor([1., 1., 1.])\n","----------------------------------------------------------------------------------------------------\n","\n","파라미터 네임 bn1.num_batches_tracked   / 사이즈: torch.Size([])\n","tensor(0)\n","----------------------------------------------------------------------------------------------------\n","\n","파라미터 네임 conv2.weight              / 사이즈: torch.Size([5, 3, 3, 3])\n","tensor([[[[ 0.0438, -0.0563,  0.1841],\n","          [-0.1251,  0.0303,  0.1361],\n","          [ 0.1639, -0.0634,  0.1633]],\n","\n","         [[ 0.0818,  0.1529, -0.0941],\n","          [-0.0265,  0.0052, -0.1295],\n","          [ 0.0255,  0.0633, -0.1325]],\n","\n","         [[-0.0132, -0.1915,  0.0679],\n","          [-0.0123, -0.1538, -0.0259],\n","          [ 0.0418, -0.0636, -0.1449]]],\n","\n","\n","        [[[ 0.1660,  0.0626, -0.0207],\n","          [ 0.1184,  0.0505,  0.1607],\n","          [ 0.0271,  0.0029, -0.0655]],\n","\n","         [[ 0.0570,  0.1269, -0.0598],\n","          [-0.1144, -0.0057, -0.1478],\n","          [ 0.0116, -0.1364,  0.0949]],\n","\n","         [[-0.0368,  0.1425,  0.1226],\n","          [-0.1515, -0.0576, -0.1652],\n","          [-0.1625, -0.1134,  0.0348]]],\n","\n","\n","        [[[-0.0241,  0.0401, -0.1508],\n","          [ 0.0248,  0.1229, -0.0724],\n","          [ 0.1214, -0.0930, -0.0724]],\n","\n","         [[ 0.1660, -0.0908,  0.0323],\n","          [-0.1402, -0.1566, -0.0711],\n","          [-0.0929,  0.1614,  0.1577]],\n","\n","         [[-0.0838, -0.1002, -0.1735],\n","          [-0.0592, -0.1302,  0.0210],\n","          [-0.1903, -0.1836, -0.0908]]],\n","\n","\n","        [[[ 0.0428, -0.1209, -0.1139],\n","          [-0.0344,  0.0199,  0.1837],\n","          [-0.0379,  0.0033, -0.0486]],\n","\n","         [[ 0.0563,  0.0794,  0.1142],\n","          [-0.0203,  0.0809,  0.1073],\n","          [ 0.0192,  0.1680,  0.0439]],\n","\n","         [[-0.1206, -0.0516,  0.1347],\n","          [ 0.1343,  0.0149, -0.1063],\n","          [-0.1427, -0.1846, -0.1880]]],\n","\n","\n","        [[[-0.1921, -0.0293,  0.0818],\n","          [ 0.1729,  0.0567, -0.1844],\n","          [-0.1860, -0.1493,  0.1460]],\n","\n","         [[-0.0037, -0.0607,  0.1816],\n","          [ 0.0812,  0.1590, -0.0378],\n","          [-0.1637, -0.1141,  0.1804]],\n","\n","         [[ 0.1892, -0.1476,  0.0403],\n","          [-0.0732,  0.0727,  0.1277],\n","          [ 0.1235,  0.0350, -0.1026]]]])\n","----------------------------------------------------------------------------------------------------\n","\n"]}],"source":["for param, weight in model.state_dict().items(): # items()를 하게 되면 리스트 안에 튜플 형식으로 값이 들어가 있음.\n","    print(f\"파라미터 네임 {param:25} / 사이즈: {weight.size()}\")\n","    print(weight)\n","    print(\"-\" * 100, end=\"\\n\\n\")"]},{"cell_type":"code","execution_count":20,"id":"Ed5j0w3rS_AI","metadata":{"id":"Ed5j0w3rS_AI"},"outputs":[{"name":"stdout","output_type":"stream","text":["model.state_dict() 의 Type : <class 'collections.OrderedDict'>\n"]},{"data":{"text/plain":["True"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["from collections import OrderedDict\n","print(f\"model.state_dict() 의 Type : {type(model.state_dict())}\") # type으로 어떤 클래스인지 확인할 수 있음\n","isinstance(model.state_dict(), OrderedDict) # model.state_dict()의 return 값은 OrderDict의 인스턴스 형식을 가진다."]},{"cell_type":"markdown","id":"aoJVB7XUS_AI","metadata":{"id":"aoJVB7XUS_AI"},"source":["#### `named_parameters()` 을 안쓰고 `state_dict()` 을 사용하는 이유가 무언인가요? (둘이 뭐가 다른가요)\n"," - `named_parameters()` : returns only parameters\n"," - `state_dict()`: returns both parameters and buffers (e.g. BN runnin_mean, running_var)\n"," \n"," [Reference](https://stackoverflow.com/a/54747245)"]},{"cell_type":"code","execution_count":21,"id":"rKBfbJJYS_AJ","metadata":{"id":"rKBfbJJYS_AJ"},"outputs":[{"name":"stdout","output_type":"stream","text":["['conv1.weight', 'conv1.bias', 'bn1.weight', 'bn1.bias', 'conv2.weight']\n","\n","['conv1.weight',\n"," 'conv1.bias',\n"," 'bn1.weight',\n"," 'bn1.bias',\n"," 'bn1.running_mean',\n"," 'bn1.running_var',\n"," 'bn1.num_batches_tracked',\n"," 'conv2.weight']\n"]}],"source":["pprint([name for (name, param) in model.named_parameters()])  # named_parameters() : returns only parameters\n","print()\n","pprint(list(model.state_dict().keys()))                       # state_dict(): retuns both parameters and buffers"]},{"cell_type":"markdown","id":"vZBCDWBfS_AJ","metadata":{"id":"vZBCDWBfS_AJ"},"source":["### CPU vs GPU\n"," - Pytorch 텐서(데이터)는 다양한 프로세서(CPU, GPU, TPU) 에서 연산 및 학습이 가능합니다.\n"," - 따라서, 특정 프로세서에서 학습을 진행하고 싶은 경우 해당 프로세스를 명시적으로 지정해주어야 합니다.\n"," - 이는 해당 텐서(데이터)를 특정 프로세스의 메모리에 load 또는 해당 프로세스의 메모리로 이동하는 것을 의미합니다.\n"," - 따라서, 연산하는 텐서들의 디바이스가 같아야만 연산이 가능합니다. 그렇지 않을 경우 에러가 발생합니다."]},{"cell_type":"markdown","id":"mmCL_sXES_AK","metadata":{"id":"mmCL_sXES_AK"},"source":["#### 새로운 텐서 생성"]},{"cell_type":"code","execution_count":22,"id":"I_EH9jgOS_AK","metadata":{"id":"I_EH9jgOS_AK"},"outputs":[{"name":"stdout","output_type":"stream","text":["데이터 디바이스: cpu\n","데이터 디바이스: cuda:0\n","데이터 디바이스: cpu\n"]}],"source":["data = torch.randn(2,2, device=torch.device('cpu'))     # CPU 에 새로운 텐서 생성\n","print(f\"데이터 디바이스: {data.device}\")\n","\n","data = torch.randn(2,2, device=torch.device('cuda:0'))  # GPU 0번에 새로운 텐서 생성\n","print(f\"데이터 디바이스: {data.device}\")\n","\n","data = torch.randn(2,2)                                 # device 를 따로 지정하지 않으면 default 로 CPU 에 생성됩니다.\n","print(f\"데이터 디바이스: {data.device}\")"]},{"cell_type":"markdown","id":"FcA2NEVmS_AK","metadata":{"id":"FcA2NEVmS_AK"},"source":["#### 이미 생성되어 있는 텐서를 다른 프로세스의 메모리로 이동하는 것도 가능합니다\n","#### .cpu()\n","모든 모델의 파라미터와 버터를 CPU 메모리로 이동"]},{"cell_type":"code","execution_count":23,"id":"c8R3ygRRS_AL","metadata":{"id":"c8R3ygRRS_AL"},"outputs":[{"name":"stdout","output_type":"stream","text":["파라미터 디바이스: cpu\n","파라미터 디바이스: cpu\n","파라미터 디바이스: cpu\n","파라미터 디바이스: cpu\n","파라미터 디바이스: cpu\n"]}],"source":["model.cpu()\n","for weight in model.parameters():\n","    print(f\"파라미터 디바이스: {weight.device}\")"]},{"cell_type":"markdown","id":"GobjlWa6S_AL","metadata":{"id":"GobjlWa6S_AL"},"source":["#### .cuda()\n","모든 모델의 파라미터와 버터를 GPU 메모리로 이동"]},{"cell_type":"code","execution_count":24,"id":"Knj_icpAS_AL","metadata":{"id":"Knj_icpAS_AL"},"outputs":[{"name":"stdout","output_type":"stream","text":["파라미터 디바이스: cuda:0\n","파라미터 디바이스: cuda:0\n","파라미터 디바이스: cuda:0\n","파라미터 디바이스: cuda:0\n","파라미터 디바이스: cuda:0\n"]}],"source":["model.cuda()\n","for weight in model.parameters():\n","    print(f\"파라미터 디바이스: {weight.device}\")"]},{"cell_type":"markdown","id":"qwOb6ccTS_AM","metadata":{"id":"qwOb6ccTS_AM"},"source":["#### .to()\n","파라미터 또는 버퍼 메모리를 다음 프로세스로 이동"]},{"cell_type":"code","execution_count":25,"id":"pEOar6EWS_AM","metadata":{"id":"pEOar6EWS_AM"},"outputs":[{"name":"stdout","output_type":"stream","text":["파라미터 디바이스를 cpu 로 변경\n","파라미터 디바이스: cpu\n","파라미터 디바이스: cpu\n","파라미터 디바이스: cpu\n","파라미터 디바이스: cpu\n","파라미터 디바이스: cpu\n","\n","파라미터 디바이스를 cuda 로 변경\n","파라미터 디바이스: cuda:0\n","파라미터 디바이스: cuda:0\n","파라미터 디바이스: cuda:0\n","파라미터 디바이스: cuda:0\n","파라미터 디바이스: cuda:0\n","\n"]}],"source":["device_options = ['cpu', 'cuda']\n","for device_option in device_options:\n","    device = torch.device(device_option)\n","    model.to(device) # 어디로 갈 것인지 명시해줘야 함\n","    \n","    print(f\"파라미터 디바이스를 {device_option} 로 변경\")\n","    for weight in model.parameters():\n","        print(f\"파라미터 디바이스: {weight.device}\")\n","    print()"]},{"cell_type":"markdown","id":"l1ve5Ky2S_AN","metadata":{"id":"l1ve5Ky2S_AN"},"source":["#### Cautions\n","\n","새로운 텐서를 GPU 에 생성하고 싶은 경우 `torch.randn(2,2).cuda()` 처럼 생성하면\n","\n","1) CPU 메모리에 텐서를 생성 2) CPU -> GPU 메모리로 값을 이동하는 과정이 일어나면서 cost efficient 하지 못합니다\n","\n","`torch.randn(2,2, device=torch.device('cuda:0'))` 와 같이 처음부터 GPU 메모리에 생성하는 것을 권장합니다."]},{"cell_type":"markdown","id":"bq7KXuyfS_AN","metadata":{"id":"bq7KXuyfS_AN"},"source":["#### Cautions\n"," - 연산하는 두 개의 텐서는 반드시 같은 device 에 존재하여야 합니다.\n"," - 그렇지 않으면 에러가 발생합니다."]},{"cell_type":"code","execution_count":26,"id":"2LjfibL_S_AN","metadata":{"id":"2LjfibL_S_AN"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 0.0566, -1.4878],\n","        [ 0.7210, -0.0824]])\n"]}],"source":["data1 = torch.randn(2,2, device=torch.device('cpu'))\n","data2 = torch.randn(2,2, device=torch.device('cpu'))\n","print(data1 + data2)  # 두 텐서가 같은 device(CPU) 에 있기에 연산이 가능합니다."]},{"cell_type":"code","execution_count":27,"id":"KpDpGzCqS_AO","metadata":{"id":"KpDpGzCqS_AO"},"outputs":[{"ename":"RuntimeError","evalue":"Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-243f39335071>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 두 텐서가 다른 device(CPU, GPU) 에 있기에 연산이 불가능합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"]}],"source":["data1 = torch.randn(2,2, device=torch.device('cpu'))\n","data2 = torch.randn(2,2, device=torch.device('cuda'))\n","print(data1 + data2)  # 두 텐서가 다른 device(CPU, GPU) 에 있기에 연산이 불가능합니다."]},{"cell_type":"markdown","id":"wcvHa8G5S_AO","metadata":{"id":"wcvHa8G5S_AO"},"source":["### forward\n"," - nn.Module 을 상속한 객체를 직접 호출할 때 수행하는 연산을 정의합니다.\n"," - `model(input)` 을 통해 모델의 예측값을 계산할 수 있습니다.\n"," - Defines the computation performed at every call"]},{"cell_type":"code","execution_count":28,"id":"UXQuTb-4S_AO","metadata":{"id":"UXQuTb-4S_AO","scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["모델 output 사이즈: torch.Size([1, 5, 8, 8])\n","tensor([[[[0.0000e+00, 0.0000e+00, 1.8332e-01, 0.0000e+00, 9.2436e-02,\n","           5.8132e-02, 2.7725e-01, 2.3128e-02],\n","          [1.2862e-01, 2.3555e-01, 2.3252e-01, 5.5072e-04, 0.0000e+00,\n","           1.1315e-02, 2.3162e-01, 1.8284e-02],\n","          [1.8082e-01, 3.8808e-01, 0.0000e+00, 0.0000e+00, 5.2625e-01,\n","           0.0000e+00, 5.6759e-02, 1.3554e-01],\n","          [3.0002e-01, 4.1064e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","           7.4283e-02, 0.0000e+00, 8.9673e-02],\n","          [6.3507e-02, 0.0000e+00, 0.0000e+00, 1.3172e-01, 0.0000e+00,\n","           7.8278e-02, 0.0000e+00, 0.0000e+00],\n","          [8.2148e-02, 0.0000e+00, 5.3025e-02, 0.0000e+00, 0.0000e+00,\n","           5.6864e-01, 0.0000e+00, 0.0000e+00],\n","          [9.1423e-02, 4.8151e-01, 8.4822e-02, 0.0000e+00, 2.6650e-01,\n","           1.6322e-01, 1.9354e-02, 0.0000e+00],\n","          [0.0000e+00, 2.8057e-02, 4.6401e-01, 0.0000e+00, 0.0000e+00,\n","           1.1520e-01, 0.0000e+00, 0.0000e+00]],\n","\n","         [[2.0650e-01, 0.0000e+00, 0.0000e+00, 6.8151e-02, 0.0000e+00,\n","           0.0000e+00, 2.8635e-02, 9.5057e-02],\n","          [0.0000e+00, 0.0000e+00, 5.8532e-01, 0.0000e+00, 1.9626e-01,\n","           0.0000e+00, 0.0000e+00, 1.3308e-01],\n","          [0.0000e+00, 3.0488e-01, 5.4850e-01, 0.0000e+00, 7.2911e-01,\n","           2.5868e-01, 0.0000e+00, 1.3515e-01],\n","          [2.3363e-01, 3.6934e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00, 3.7094e-01, 0.0000e+00],\n","          [2.8884e-01, 0.0000e+00, 0.0000e+00, 4.4388e-01, 0.0000e+00,\n","           3.1875e-01, 0.0000e+00, 3.4644e-02],\n","          [0.0000e+00, 9.6507e-02, 3.1853e-01, 2.2381e-01, 0.0000e+00,\n","           1.5415e-02, 0.0000e+00, 7.7193e-01],\n","          [0.0000e+00, 2.1695e-01, 0.0000e+00, 3.8327e-01, 6.3133e-02,\n","           0.0000e+00, 3.0993e-01, 2.7685e-01],\n","          [0.0000e+00, 0.0000e+00, 3.2135e-01, 5.7391e-01, 0.0000e+00,\n","           7.6589e-02, 0.0000e+00, 0.0000e+00]],\n","\n","         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1586e-02,\n","           0.0000e+00, 0.0000e+00, 0.0000e+00],\n","          [0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9189e-01, 0.0000e+00,\n","           0.0000e+00, 1.1664e-01, 0.0000e+00],\n","          [0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9028e-01, 0.0000e+00,\n","           1.9782e-01, 0.0000e+00, 0.0000e+00],\n","          [0.0000e+00, 6.4046e-02, 3.0980e-01, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00, 0.0000e+00, 0.0000e+00],\n","          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00, 0.0000e+00, 0.0000e+00],\n","          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00, 0.0000e+00, 0.0000e+00],\n","          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1641e-01,\n","           3.8761e-02, 0.0000e+00, 2.4177e-01],\n","          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00, 2.3295e-01, 0.0000e+00]],\n","\n","         [[3.0564e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00, 9.9027e-02, 0.0000e+00],\n","          [0.0000e+00, 0.0000e+00, 7.1535e-01, 1.8875e-01, 1.5787e-01,\n","           1.7490e-01, 0.0000e+00, 1.0873e-01],\n","          [8.0118e-02, 4.9373e-01, 0.0000e+00, 0.0000e+00, 3.6073e-01,\n","           0.0000e+00, 1.5739e-02, 1.0975e-02],\n","          [7.3691e-02, 1.6852e-02, 0.0000e+00, 2.3690e-01, 0.0000e+00,\n","           0.0000e+00, 2.7547e-01, 2.3690e-01],\n","          [0.0000e+00, 0.0000e+00, 1.3661e-01, 1.5220e-01, 2.4272e-01,\n","           6.7166e-01, 0.0000e+00, 0.0000e+00],\n","          [0.0000e+00, 4.2558e-01, 5.7746e-01, 0.0000e+00, 0.0000e+00,\n","           0.0000e+00, 8.2102e-02, 2.9216e-01],\n","          [3.2805e-01, 1.3167e-01, 0.0000e+00, 3.0013e-01, 1.0510e-01,\n","           8.6038e-02, 2.8753e-01, 0.0000e+00],\n","          [1.8148e-01, 0.0000e+00, 5.7173e-01, 0.0000e+00, 0.0000e+00,\n","           2.3156e-03, 0.0000e+00, 0.0000e+00]],\n","\n","         [[0.0000e+00, 3.1796e-01, 6.7263e-01, 2.7435e-01, 0.0000e+00,\n","           8.9271e-05, 0.0000e+00, 3.7524e-02],\n","          [1.0037e-01, 5.0688e-01, 0.0000e+00, 0.0000e+00, 1.1008e+00,\n","           0.0000e+00, 1.8060e-01, 0.0000e+00],\n","          [4.0286e-01, 0.0000e+00, 2.3464e-02, 6.9704e-01, 0.0000e+00,\n","           1.8957e-01, 2.7576e-01, 0.0000e+00],\n","          [0.0000e+00, 0.0000e+00, 1.3029e-01, 1.7221e-01, 3.8633e-02,\n","           4.2940e-01, 0.0000e+00, 0.0000e+00],\n","          [5.6736e-03, 3.8106e-01, 4.7389e-01, 0.0000e+00, 3.3615e-01,\n","           1.5932e-01, 1.1606e-01, 9.6092e-01],\n","          [9.6122e-02, 0.0000e+00, 2.7445e-01, 1.3193e-02, 3.1058e-01,\n","           0.0000e+00, 6.1516e-01, 0.0000e+00],\n","          [1.3507e-01, 0.0000e+00, 3.0802e-01, 0.0000e+00, 0.0000e+00,\n","           2.6403e-01, 0.0000e+00, 0.0000e+00],\n","          [1.5805e-01, 5.3658e-01, 0.0000e+00, 0.0000e+00, 5.9830e-01,\n","           0.0000e+00, 0.0000e+00, 3.5019e-01]]]], device='cuda:0',\n","       grad_fn=<ReluBackward0>)\n"]}],"source":["dummy_input = torch.randn(1, 1, 12, 12, device=device) # 모델과 연산할 데이터도 같은 공간으로 이동시켜야 함\n","model.to(device)\n","output = model(dummy_input) # model.forward(dummy_input) 과 동일함.\n","print(f\"모델 output 사이즈: {output.size()}\")\n","print(output)"]},{"cell_type":"markdown","id":"IrbF9fD9S_AP","metadata":{"id":"IrbF9fD9S_AP"},"source":["#### Cautions\n"," - 위에서 말씀드린 것과 같은 원리로 모델과 인풋의 device 는 반드시 같아야 합니다."]},{"cell_type":"code","execution_count":29,"id":"o-pjTeVaS_AP","metadata":{"id":"o-pjTeVaS_AP"},"outputs":[{"name":"stdout","output_type":"stream","text":["모델 ouput 사이즈: torch.Size([1, 5, 8, 8])\n"]}],"source":["cpu_device = torch.device('cpu')\n","gpu_device = torch.device('cuda')\n","\n","# device is same\n","dummy_input = dummy_input.to(gpu_device)\n","model.to(gpu_device)\n","output = model(dummy_input)  # 잘 작동합니다 \n","print(f\"모델 ouput 사이즈: {output.size()}\")"]},{"cell_type":"code","execution_count":30,"id":"aAwqrvnpS_AP","metadata":{"id":"aAwqrvnpS_AP","scrolled":true},"outputs":[{"ename":"RuntimeError","evalue":"Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _thnn_conv2d_forward","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-92144b071d21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# device is different\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_input\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 에러 발생\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"모델 ouput 사이즈: {output.size()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-5f680354f5ab>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    417\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 419\u001b[0;31m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0m\u001b[1;32m    420\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _thnn_conv2d_forward"]}],"source":["dummy_input = dummy_input.to(cpu_device)\n","model.to(gpu_device)\n","\n","# device is different\n","# RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same\n","output = model(dummy_input)  # 에러 발생\n","print(f\"모델 ouput 사이즈: {output.size()}\")"]},{"cell_type":"markdown","id":"P8ThIO4jS_AQ","metadata":{"id":"P8ThIO4jS_AQ"},"source":["### requires_grad()\n"," - autograd 가 해당 모델의 연산을 기록할지를 결정합니다\n"," - false 일 시, 수행하는 연산을 기록하지 않고 따라서 역전파가 되지 않아 학습에서 제외됩니다.\n"," - Change if autograd should record operations on parameters in this module."]},{"cell_type":"code","execution_count":31,"id":"ixAWEZ3iS_AQ","metadata":{"id":"ixAWEZ3iS_AQ"},"outputs":[{"name":"stdout","output_type":"stream","text":["파라미터 conv1.weight    가 gradient 를 tracking 하나요? -> False\n","파라미터 conv1.bias      가 gradient 를 tracking 하나요? -> False\n","파라미터 bn1.weight      가 gradient 를 tracking 하나요? -> False\n","파라미터 bn1.bias        가 gradient 를 tracking 하나요? -> False\n","파라미터 conv2.weight    가 gradient 를 tracking 하나요? -> False\n"]}],"source":["# requires_grad = False\n","model.requires_grad_(requires_grad=False) # attribute가 아닌 method로 쓰려면 require_grad_()\n","for param, weight in model.named_parameters():\n","    print(f\"파라미터 {param:15} 가 gradient 를 tracking 하나요? -> {weight.requires_grad}\") # attribute"]},{"cell_type":"code","execution_count":32,"id":"rysdVfBOS_AR","metadata":{"id":"rysdVfBOS_AR"},"outputs":[{"name":"stdout","output_type":"stream","text":["파라미터 conv1.weight    가 gradient 를 tracking 하나요? -> True\n","파라미터 conv1.bias      가 gradient 를 tracking 하나요? -> True\n","파라미터 bn1.weight      가 gradient 를 tracking 하나요? -> True\n","파라미터 bn1.bias        가 gradient 를 tracking 하나요? -> True\n","파라미터 conv2.weight    가 gradient 를 tracking 하나요? -> True\n"]}],"source":["# requires_grad = True\n","model.requires_grad_(requires_grad=True)\n","for param, weight in model.named_parameters():\n","    print(f\"파라미터 {param:15} 가 gradient 를 tracking 하나요? -> {weight.requires_grad}\")"]},{"cell_type":"markdown","id":"4oj9DI74S_AR","metadata":{"id":"4oj9DI74S_AR"},"source":["### train(), eval()\n"," - 모델을 training(evaluation) 모드로 전환합니다.\n"," - training 과 evaluation 이 다르게 작용하는 모듈들(Dropout, BatchNorm) 에 영향을 줍니다.\n"," - 학습 단계에서는 training 모드로, 인퍼런스 단계에서는 eval 모드로 전환해주어야 합니다.\n"," - [아래](https://github.com/pytorch/pytorch/blob/1.6/torch/nn/modules/batchnorm.py#L110-L117)는 BatchNorm2d 의 파이토치 구현입니다. `self.training=True` 일 경우에만, `running_mean`, `running_var` 을 tracking 합니다.\n"," \n","```\n","if self.training and self.track_running_stats:\n","    # TODO: if statement only here to tell the jit to skip emitting this when it is None\n","    if self.num_batches_tracked is not None:\n","        self.num_batches_tracked = self.num_batches_tracked + 1\n","        if self.momentum is None:  # use cumulative moving average\n","            exponential_average_factor = 1.0 / float(self.num_batches_tracked)\n","        else:  # use exponential moving average\n","            exponential_average_factor = self.momentum\n","```"]},{"cell_type":"code","execution_count":33,"id":"tCxiUYFmS_AS","metadata":{"id":"tCxiUYFmS_AS"},"outputs":[{"name":"stdout","output_type":"stream","text":["model.bn1.training: True\n"]}],"source":["model.train()  # train mode 로 전환\n","print(f\"model.bn1.training: {model.bn1.training}\")\n","# model.bn1 : BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)"]},{"cell_type":"code","execution_count":34,"id":"NoQ2axpcS_AS","metadata":{"id":"NoQ2axpcS_AS"},"outputs":[{"name":"stdout","output_type":"stream","text":["model.bn1.training: False\n"]}],"source":["model.eval()  # eval mode 로 전환\n","print(f\"model.bn1.training: {model.bn1.training}\")"]},{"cell_type":"markdown","id":"Jvvl6abnS_AS","metadata":{"id":"Jvvl6abnS_AS"},"source":["### 파이토치 공식 문서에서 nn.Module 에 관한 더 많은 정보를 얻을 수 있습니다.\n","https://pytorch.org/docs/stable/generated/torch.nn.Module.html\n","\n","궁금증이 생기면 공식 문서를 참고하는걸 강력 추천합니다."]}],"metadata":{"colab":{"collapsed_sections":[],"name":"5_Model (정답).ipynb의 사본","provenance":[{"file_id":"1twV1GbaiVefp02nx2qB3lYWl5REVy26v","timestamp":1645694958873}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":5}
